[
  {
    "objectID": "numpy.html",
    "href": "numpy.html",
    "title": "Numpy",
    "section": "",
    "text": "!pip list | grep numpy\n\nnumpy                         1.23.5\n\n\n\nimport numpy as np"
  },
  {
    "objectID": "numpy.html#import-numpy",
    "href": "numpy.html#import-numpy",
    "title": "Numpy",
    "section": "",
    "text": "!pip list | grep numpy\n\nnumpy                         1.23.5\n\n\n\nimport numpy as np"
  },
  {
    "objectID": "numpy.html#creating-numpy-arrays",
    "href": "numpy.html#creating-numpy-arrays",
    "title": "Numpy",
    "section": "Creating Numpy Arrays",
    "text": "Creating Numpy Arrays\n\nPython sequences to NumPy Arrays\n\na1D = np.array([1, 2, 3, 4])\n\na2D = np.array([[1, 2], [3, 4]])\n\na3D = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n\na1D, a2D, a3D\n\n(array([1, 2, 3, 4]),\n array([[1, 2],\n        [3, 4]]),\n array([[[1, 2],\n         [3, 4]],\n \n        [[5, 6],\n         [7, 8]]]))\n\n\n\na = np.array([127, 128, 129], dtype=np.int8)\na\n\narray([ 127, -128, -127], dtype=int8)\n\n\n\n\nIntrinsic NumPy array creation functions\n\nnp.arange(10)\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\nnp.arange(2, 10, dtype=float)\n\narray([2., 3., 4., 5., 6., 7., 8., 9.])\n\n\n\nnp.arange(2, 3, 0.1)\n\narray([2. , 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9])\n\n\n\nnp.linspace(1., 4., 6)\n\narray([1. , 1.6, 2.2, 2.8, 3.4, 4. ])\n\n\n\nnp.eye(3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\nnp.eye(3, 5)\n\narray([[1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.]])\n\n\n\nnp.diag([1, 2, 3])\n\narray([[1, 0, 0],\n       [0, 2, 0],\n       [0, 0, 3]])\n\n\n\nnp.diag([1, 2, 3], 1)\n\narray([[0, 1, 0, 0],\n       [0, 0, 2, 0],\n       [0, 0, 0, 3],\n       [0, 0, 0, 0]])\n\n\n\nnp.vander(np.linspace(0, 2, 5), 3)\n\narray([[0.  , 0.  , 1.  ],\n       [0.25, 0.5 , 1.  ],\n       [1.  , 1.  , 1.  ],\n       [2.25, 1.5 , 1.  ],\n       [4.  , 2.  , 1.  ]])\n\n\n\nnp.zeros((2, 3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.ones((2, 3, 2))\n\narray([[[1., 1.],\n        [1., 1.],\n        [1., 1.]],\n\n       [[1., 1.],\n        [1., 1.],\n        [1., 1.]]])\n\n\n\nfrom numpy.random import default_rng\ndefault_rng(42).random((2,3))\n\narray([[0.77395605, 0.43887844, 0.85859792],\n       [0.69736803, 0.09417735, 0.97562235]])\n\n\n\nnp.indices((3,3))\n\narray([[[0, 0, 0],\n        [1, 1, 1],\n        [2, 2, 2]],\n\n       [[0, 1, 2],\n        [0, 1, 2],\n        [0, 1, 2]]])\n\n\n\n\nReplicating, joining, or mutating existing arrays\n\na = np.array([1, 2, 3, 4, 5, 6])\n\nb = a[:2]\n\nb += 1\n\nprint('a =', a, '; b =', b)\n\na = [2 3 3 4 5 6] ; b = [2 3]\n\n\n\na = np.array([1, 2, 3, 4])\n\nb = a[:2].copy()\n\nb += 1\n\nprint('a = ', a, 'b = ', b)\n\na =  [1 2 3 4] b =  [2 3]\n\n\n\nA = np.ones((2, 2))\n\nB = np.eye(2, 2)\n\nC = np.zeros((2, 2))\n\nD = np.diag((-3, -4))\n\nnp.block([[A, B], [C, D]])\n\narray([[ 1.,  1.,  1.,  0.],\n       [ 1.,  1.,  0.,  1.],\n       [ 0.,  0., -3.,  0.],\n       [ 0.,  0.,  0., -4.]])"
  },
  {
    "objectID": "numpy.html#indexing",
    "href": "numpy.html#indexing",
    "title": "Numpy",
    "section": "Indexing",
    "text": "Indexing\n\nBasic indexing\n\nx = np.arange(10)\nx,x[2]\n\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 2)\n\n\n\nx[-2]\n\n8\n\n\n\nx.shape = (2, 5)  # now x is 2-dimensional\n\nx, x[1, 3]\n\n(array([[0, 1, 2, 3, 4],\n        [5, 6, 7, 8, 9]]),\n 8)\n\n\n\nx[0], x[0][2]\n\n(array([0, 1, 2, 3, 4]), 2)\n\n\n\nSlicing and striding\n\nx = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nx[1:7:2]\n\narray([1, 3, 5])\n\n\n\nx[-2:10]\n\narray([8, 9])\n\n\n\nx[-3:3:-1]\n\narray([7, 6, 5, 4])\n\n\n\nx[5:]\n\narray([5, 6, 7, 8, 9])\n\n\n\nx = np.array([[[1],[2],[3]], [[4],[5],[6]]])\n\nx.shape, x[1:2]\n\n((2, 3, 1),\n array([[[4],\n         [5],\n         [6]]]))\n\n\n\n\nDimensional indexing tools\n\nx[..., 0]\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\nx[:, :, 0]\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\nx[:, np.newaxis, :, :].shape\n\n(2, 1, 3, 1)\n\n\n\nx[:, None, :, :].shape\n\n(2, 1, 3, 1)\n\n\n\nx = np.arange(5)\nx\n\narray([0, 1, 2, 3, 4])\n\n\n\nx[:, np.newaxis] + x[np.newaxis, :]\n\narray([[0, 1, 2, 3, 4],\n       [1, 2, 3, 4, 5],\n       [2, 3, 4, 5, 6],\n       [3, 4, 5, 6, 7],\n       [4, 5, 6, 7, 8]])\n\n\n\n\n\nAdvanced indexing\n\nx = np.arange(10, 1, -1)\n\n\nx[np.array([3, 3, 1, 8])]\n\narray([7, 7, 9, 2])\n\n\n\nx = np.array([[1, 2], [3, 4], [5, 6]])\n\n\ny = np.arange(35).reshape(5, 7)\n\ny\n\narray([[ 0,  1,  2,  3,  4,  5,  6],\n       [ 7,  8,  9, 10, 11, 12, 13],\n       [14, 15, 16, 17, 18, 19, 20],\n       [21, 22, 23, 24, 25, 26, 27],\n       [28, 29, 30, 31, 32, 33, 34]])\n\n\n\ny[np.array([0, 2, 4]), np.array([0, 1, 2])]\n\narray([ 0, 15, 30])\n\n\n\ny[np.array([0, 2, 4]), 1]\n\narray([ 1, 15, 29])\n\n\n\ny[np.array([0, 2, 4])]\n\narray([[ 0,  1,  2,  3,  4,  5,  6],\n       [14, 15, 16, 17, 18, 19, 20],\n       [28, 29, 30, 31, 32, 33, 34]])\n\n\n\nx = np.array([[1, 2], [3, 4], [5, 6]])\n\nx[[0, 1, 2], [0, 1, 0]]\n\narray([1, 4, 5])\n\n\n\nx = np.array([[ 0,  1,  2],\n\n              [ 3,  4,  5],\n\n              [ 6,  7,  8],\n\n              [ 9, 10, 11]])\n\nrows = np.array([[0, 0],\n\n                 [3, 3]], dtype=np.intp)\n\ncolumns = np.array([[0, 2],\n\n                    [0, 2]], dtype=np.intp)\n\nx[rows, columns]\n\narray([[ 0,  2],\n       [ 9, 11]])\n\n\n\nrows = np.array([0, 3], dtype=np.intp)\n\ncolumns = np.array([0, 2], dtype=np.intp)\n\nrows[:, np.newaxis]\n\narray([[0],\n       [3]])\n\n\n\nx[rows[:, np.newaxis], columns]\n\narray([[ 0,  2],\n       [ 9, 11]])\n\n\n\nx[np.ix_(rows, columns)]\n\narray([[ 0,  2],\n       [ 9, 11]])\n\n\n\nx = np.array([[1., 2.], [np.nan, 3.], [np.nan, np.nan]])\n\nx[~np.isnan(x)]\n\narray([1., 2., 3.])\n\n\n\nx = np.array([1., -1., -2., 3])\n\nx[x &lt; 0] += 20\n\nx\n\narray([ 1., 19., 18.,  3.])\n\n\n\nx = np.arange(35).reshape(5, 7)\n\nb = x &gt; 20\nb\n\narray([[False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [ True,  True,  True,  True,  True,  True,  True],\n       [ True,  True,  True,  True,  True,  True,  True]])\n\n\n\nb[:, 5]\n\narray([False, False, False,  True,  True])\n\n\n\nx[b[:, 5]]\n\narray([[21, 22, 23, 24, 25, 26, 27],\n       [28, 29, 30, 31, 32, 33, 34]])\n\n\n\nx = np.array([[ 0,  1,  2],\n\n              [ 3,  4,  5],\n\n              [ 6,  7,  8],\n\n              [ 9, 10, 11]])\n\nrows = (x.sum(-1) % 2) == 0\n\nrows\n\narray([False,  True, False,  True])\n\n\n\ncolumns = [0, 2]\n\nx[np.ix_(rows, columns)]\n\narray([[ 3,  5],\n       [ 9, 11]])\n\n\n\nrows = rows.nonzero()[0]\n\nx[rows[:, np.newaxis], columns]\n\narray([[ 3,  5],\n       [ 9, 11]])\n\n\n\nx = np.arange(30).reshape(2, 3, 5)\n\nx\n\narray([[[ 0,  1,  2,  3,  4],\n        [ 5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14]],\n\n       [[15, 16, 17, 18, 19],\n        [20, 21, 22, 23, 24],\n        [25, 26, 27, 28, 29]]])\n\n\n\nb = np.array([[True, True, False], [False, True, True]])\n\nx[b]\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [20, 21, 22, 23, 24],\n       [25, 26, 27, 28, 29]])\n\n\n\ny = np.arange(35).reshape(5,7)\n\ny[np.array([0, 2, 4]), 1:3]\n\narray([[ 1,  2],\n       [15, 16],\n       [29, 30]])\n\n\n\ny[:, 1:3][np.array([0, 2, 4]), :]\n\narray([[ 1,  2],\n       [15, 16],\n       [29, 30]])\n\n\n\nx = np.array([[ 0,  1,  2],\n\n              [ 3,  4,  5],\n\n              [ 6,  7,  8],\n\n              [ 9, 10, 11]])\n\nx[1:2, 1:3]\n\narray([[4, 5]])\n\n\n\nx[1:2, [1, 2]]\n\narray([[4, 5]])\n\n\n\nx = np.arange(35).reshape(5, 7)\n\nb = x &gt; 20\n\nb\n\narray([[False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [False, False, False, False, False, False, False],\n       [ True,  True,  True,  True,  True,  True,  True],\n       [ True,  True,  True,  True,  True,  True,  True]])\n\n\n\nx[b[:, 5], 1:3]\n\narray([[22, 23],\n       [29, 30]])\n\n\n\n\nField Access\n\nx = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])\nx\n\narray([[(0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]),\n        (0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])],\n       [(0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]),\n        (0, [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])]],\n      dtype=[('a', '&lt;i4'), ('b', '&lt;f8', (3, 3))])\n\n\n\nx['a'].shape, x['b'].shape\n\n((2, 2), (2, 2, 3, 3))\n\n\n\nx['a'].dtype, x['b'].dtype\n\n(dtype('int32'), dtype('float64'))\n\n\n\n\nAssigning values to indexed arrays\n\nx = np.arange(10)\n\nx[2:7] = 1\n\n\nx[2:7] = np.arange(5)\n\n\nx[1] = 1.2\n\nx[1]\n\n1\n\n\n\nx = np.arange(0, 50, 10)\nx\n\narray([ 0, 10, 20, 30, 40])\n\n\n\nx[np.array([1, 1, 3, 1])] += 1\n\nx\n\narray([ 0, 11, 20, 31, 40])\n\n\n\n\nDealing with variable numbers of indices within programs\n\nz = np.arange(81).reshape(3, 3, 3, 3)\n\nindices = (1, 1, 1, 1)\n\nz[indices]\n\n40\n\n\n\nindices = (1, 1, 1, slice(0, 2))  # same as [1, 1, 1, 0:2]\n\nz[indices]\n\narray([39, 40])\n\n\n\nindices = (1, Ellipsis, 1)  # same as [1, ..., 1]\n\nz[indices]\n\narray([[28, 31, 34],\n       [37, 40, 43],\n       [46, 49, 52]])\n\n\n\nz[[1, 1, 1, 1]]  # produces a large array\n\narray([[[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]],\n\n\n       [[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]],\n\n\n       [[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]],\n\n\n       [[[27, 28, 29],\n         [30, 31, 32],\n         [33, 34, 35]],\n\n        [[36, 37, 38],\n         [39, 40, 41],\n         [42, 43, 44]],\n\n        [[45, 46, 47],\n         [48, 49, 50],\n         [51, 52, 53]]]])\n\n\n\nz[(1, 1, 1, 1)]  # returns a single value\n\n40"
  },
  {
    "objectID": "numpy.html#io-with-numpy",
    "href": "numpy.html#io-with-numpy",
    "title": "Numpy",
    "section": "I/O with Numpy",
    "text": "I/O with Numpy\n\nSplitting the lines into columns\n\nimport numpy as np\n\nfrom io import StringIO\n\n\ndata = u\"1, 2, 3\\n4, 5, 6\"\n\nnp.genfromtxt(StringIO(data), delimiter=\",\")\n\narray([[1., 2., 3.],\n       [4., 5., 6.]])\n\n\n\ndata = u\"  1  2  3\\n  4  5 67\\n890123  4\"\n\nnp.genfromtxt(StringIO(data), delimiter=3)\n\narray([[  1.,   2.,   3.],\n       [  4.,   5.,  67.],\n       [890., 123.,   4.]])\n\n\n\ndata = u\"123456789\\n   4  7 9\\n   4567 9\"\n\nnp.genfromtxt(StringIO(data), delimiter=(4, 3, 2))\n\narray([[1234.,  567.,   89.],\n       [   4.,    7.,    9.],\n       [   4.,  567.,    9.]])\n\n\n\ndata = u\"1, abc , 2\\n 3, xxx, 4\"\n\n# Without autostrip\n\nnp.genfromtxt(StringIO(data), delimiter=\",\", dtype=\"|U5\")\n\narray([['1', ' abc ', ' 2'],\n       ['3', ' xxx', ' 4']], dtype='&lt;U5')\n\n\n\nnp.genfromtxt(StringIO(data), delimiter=\",\", dtype=\"|U5\", autostrip=True)\n\narray([['1', 'abc', '2'],\n       ['3', 'xxx', '4']], dtype='&lt;U5')\n\n\n\ndata = u\"\"\"#\n\n# Skip me !\n\n# Skip me too !\n\n1, 2\n\n3, 4\n\n5, 6 #This is the third line of the data\n\n7, 8\n\n# And here comes the last line\n\n9, 0\n\n\"\"\"\n\nnp.genfromtxt(StringIO(data), comments=\"#\", delimiter=\",\")\n\narray([[1., 2.],\n       [3., 4.],\n       [5., 6.],\n       [7., 8.],\n       [9., 0.]])\n\n\n\n\nSkipping lines and choosing columns\n\ndata = u\"\\n\".join(str(i) for i in range(10))\n\nnp.genfromtxt(StringIO(data),)\n\narray([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n\n\n\nnp.genfromtxt(StringIO(data),\n              skip_header=3, skip_footer=5)\n\narray([3., 4.])\n\n\n\ndata = u\"1 2 3\\n4 5 6\"\n\nnp.genfromtxt(StringIO(data), usecols=(0, -1))\n\narray([[1., 3.],\n       [4., 6.]])\n\n\n\ndata = u\"1 2 3\\n4 5 6\"\n\nnp.genfromtxt(StringIO(data),\n              names=\"a, b, c\", usecols=(\"a\", \"c\"))\n\narray([(1., 3.), (4., 6.)], dtype=[('a', '&lt;f8'), ('c', '&lt;f8')])\n\n\n\nnp.genfromtxt(StringIO(data),\n              names=\"a, b, c\", usecols=(\"a, c\"))\n\narray([(1., 3.), (4., 6.)], dtype=[('a', '&lt;f8'), ('c', '&lt;f8')])\n\n\n\n\nChoosing the data type\nThe main way to control how the sequences of strings we have read from the file are converted to other types is to set the dtype argument. Acceptable values for this argument are:\n\na single type, such as dtype=float. The output will be 2D with the given dtype, unless a name has been associated with each column with the use of the names argument (see below). Note that dtype=float is the default for genfromtxt.\na sequence of types, such as dtype=(int, float, float).\na comma-separated string, such as dtype=“i4,f8,|U3”.\na dictionary with two keys ‘names’ and ‘formats’.\na sequence of tuples (name, type), such as dtype=[(‘A’, int), (‘B’, float)].\nan existing numpy.dtype object.\nthe special value None. In that case, the type of the columns will be determined from the data itself (see below).\n\nIn all the cases but the first one, the output will be a 1D array with a structured dtype. This dtype has as many fields as items in the sequence. The field names are defined with the names keyword.\nWhen dtype=None, the type of each column is determined iteratively from its data. We start by checking whether a string can be converted to a boolean (that is, if the string matches true or false in lower cases); then whether it can be converted to an integer, then to a float, then to a complex and eventually to a string.\nThe option dtype=None is provided for convenience. However, it is significantly slower than setting the dtype explicitly.\n\n\nSetting the names\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\na = np.genfromtxt(data, dtype=[(_, int) for _ in \"abc\"])\na\n\narray([(1, 2, 3), (4, 5, 6)],\n      dtype=[('a', '&lt;i8'), ('b', '&lt;i8'), ('c', '&lt;i8')])\n\n\n\na['a']\n\narray([1, 4])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, names=\"A, B, C\")\n\narray([(1., 2., 3.), (4., 5., 6.)],\n      dtype=[('A', '&lt;f8'), ('B', '&lt;f8'), ('C', '&lt;f8')])\n\n\n\ndata = StringIO(\"So it goes\\n#a b c\\n1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, skip_header=1, names=True)\n\narray([(1., 2., 3.), (4., 5., 6.)],\n      dtype=[('a', '&lt;f8'), ('b', '&lt;f8'), ('c', '&lt;f8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nndtype=[('a',int), ('b', float), ('c', int)]\n\nnames = [\"A\", \"B\", \"C\"]\n\nnp.genfromtxt(data, names=names, dtype=ndtype)\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('A', '&lt;i8'), ('B', '&lt;f8'), ('C', '&lt;i8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, dtype=(int, float, int))\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f8'), ('f2', '&lt;i8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, dtype=(int, float, int), names=\"a\")\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('a', '&lt;i8'), ('f0', '&lt;f8'), ('f1', '&lt;i8')])\n\n\n\ndata = StringIO(\"1 2 3\\n 4 5 6\")\n\nnp.genfromtxt(data, dtype=(int, float, int), defaultfmt=\"var_%02i\")\n\narray([(1, 2., 3), (4, 5., 6)],\n      dtype=[('var_00', '&lt;i8'), ('var_01', '&lt;f8'), ('var_02', '&lt;i8')])\n\n\n\n\nTweaking the conversion\n\nconvertfunc = lambda x: float(x.strip(b\"%\"))/100.\n\ndata = u\"1, 2.3%, 45.\\n6, 78.9%, 0\"\n\nnames = (\"i\", \"p\", \"n\")\n\n# General case .....\nnp.genfromtxt(StringIO(data), delimiter=\",\", names=names)\n\narray([(1., nan, 45.), (6., nan,  0.)],\n      dtype=[('i', '&lt;f8'), ('p', '&lt;f8'), ('n', '&lt;f8')])\n\n\n\n# Converted case ...\nnp.genfromtxt(StringIO(data), delimiter=\",\", names=names,\n              converters={1: convertfunc})\n\narray([(1., 0.023, 45.), (6., 0.789,  0.)],\n      dtype=[('i', '&lt;f8'), ('p', '&lt;f8'), ('n', '&lt;f8')])\n\n\n\n# Using a name for the converter ...\n\nnp.genfromtxt(StringIO(data), delimiter=\",\", names=names,\n              converters={\"p\": convertfunc})\n\narray([(1., 0.023, 45.), (6., 0.789,  0.)],\n      dtype=[('i', '&lt;f8'), ('p', '&lt;f8'), ('n', '&lt;f8')])\n\n\n\ndata = u\"1, , 3\\n 4, 5, 6\"\n\nconvert = lambda x: float(x.strip() or -999)\n\nnp.genfromtxt(StringIO(data), delimiter=\",\",\n\n              converters={1: convert})\n\narray([[   1., -999.,    3.],\n       [   4.,    5.,    6.]])\n\n\n\ndata = u\"N/A, 2, 3\\n4, ,???\"\n\nkwargs = dict(delimiter=\",\",\n\n              dtype=int,\n\n              names=\"a,b,c\",\n\n              missing_values={0:\"N/A\", 'b':\" \", 2:\"???\"},\n\n              filling_values={0:0, 'b':0, 2:-999})\n\nnp.genfromtxt(StringIO(data), **kwargs)\n\narray([(0, 2,    3), (4, 0, -999)],\n      dtype=[('a', '&lt;i8'), ('b', '&lt;i8'), ('c', '&lt;i8')])"
  },
  {
    "objectID": "numpy.html#data-types",
    "href": "numpy.html#data-types",
    "title": "Numpy",
    "section": "Data types",
    "text": "Data types\n\nArray types and conversions between types\n\n\n\n\n\n\n\n\nNumpy type\nC type\nDescription\n\n\n\n\nnumpy.bool_\nbool\nBoolean (True or False) stored as a byte\n\n\nnumpy.byte\nsigned char\nPlatform-defined\n\n\nnumpy.ubyte\nunsigned char\nPlatform-defined\n\n\nnumpy.short\nshort\nPlatform-defined\n\n\nnumpy.ushort\nunsigned short\nPlatform-defined\n\n\nnumpy.intc\nint\nPlatform-defined\n\n\nnumpy.uintc\nunsigned int\nPlatform-defined\n\n\nnumpy.int_\nlong\nPlatform-defined\n\n\nnumpy.uint\nunsigned long\nPlatform-defined\n\n\nnumpy.longlong\nlong long\nPlatform-defined\n\n\nnumpy.ulonglong\nunsigned long long\nPlatform-defined\n\n\nnumpy.half / numpy.float16\n\nHalf precision float: sign bit, 5 bits exponent, 10 bits mantissa\n\n\nnumpy.single\nfloat\nPlatform-defined single precision float: typically sign bit, 8 bits exponent, 23 bits mantissa\n\n\nnumpy.double\ndouble\nPlatform-defined double precision float: typically sign bit, 11 bits exponent, 52 bits mantissa.\n\n\nnumpy.longdouble\nlong double\nPlatform-defined extended-precision float\n\n\nnumpy.csingle\nfloat complex\nComplex number, represented by two single-precision floats (real and imaginary components)\n\n\nnumpy.cdouble\ndouble complex\nComplex number, represented by two double-precision floats (real and imaginary components).\n\n\nnumpy.clongdouble\nlong double complex\nComplex number, represented by two extended-precision floats (real and imaginary components).\n\n\n\n\nx = np.float32(1.0)\n\nx\n\n1.0\n\n\n\ny = np.int_([1,2,4])\n\ny\n\narray([1, 2, 4])\n\n\n\nz = np.arange(3, dtype=np.uint8)\n\nz\n\narray([0, 1, 2], dtype=uint8)\n\n\n\nnp.array([1, 2, 3], dtype='f')\n\narray([1., 2., 3.], dtype=float32)\n\n\n\nz.astype(float)\n\narray([0., 1., 2.])\n\n\n\nnp.int8(z)\n\narray([0, 1, 2], dtype=int8)\n\n\n\nz.dtype\n\ndtype('uint8')\n\n\n\nd = np.dtype(int)\n\nd\n\ndtype('int64')\n\n\n\nnp.issubdtype(d, np.integer)\n\nTrue\n\n\n\nnp.issubdtype(d, np.floating)\n\nFalse\n\n\n\nnp.power(100, 8, dtype=np.int64)\n\n10000000000000000\n\n\n\nnp.power(100, 8, dtype=np.int32)\n\n1874919424\n\n\n\nnp.iinfo(int) # Bounds of the default integer on this system.\n\niinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n\n\n\nnp.iinfo(np.int32) # Bounds of a 32-bit integer\n\niinfo(min=-2147483648, max=2147483647, dtype=int32)\n\n\n\nnp.iinfo(np.int64) # Bounds of a 64-bit integer\n\niinfo(min=-9223372036854775808, max=9223372036854775807, dtype=int64)\n\n\n\nnp.power(100, 100, dtype=np.int64) # Incorrect even with 64-bit int\n\n0\n\n\n\nnp.power(100, 100, dtype=np.float64)\n\n1e+200"
  },
  {
    "objectID": "numpy.html#broadcastable-arrays",
    "href": "numpy.html#broadcastable-arrays",
    "title": "Numpy",
    "section": "Broadcastable arrays",
    "text": "Broadcastable arrays\n\na = np.array([1.0, 2.0, 3.0])\n\nb = np.array([2.0, 2.0, 2.0])\n\na * b\n\narray([2., 4., 6.])\n\n\n\na = np.array([1.0, 2.0, 3.0])\n\nb = 2.0\n\na * b\n\narray([2., 4., 6.])\n\n\n\na = np.array([[ 0.0,  0.0,  0.0],\n\n              [10.0, 10.0, 10.0],\n\n              [20.0, 20.0, 20.0],\n\n              [30.0, 30.0, 30.0]])\n\nb = np.array([1.0, 2.0, 3.0])\n\na + b\n\narray([[ 1.,  2.,  3.],\n       [11., 12., 13.],\n       [21., 22., 23.],\n       [31., 32., 33.]])\n\n\n\na = np.array([0.0, 10.0, 20.0, 30.0])\n\nb = np.array([1.0, 2.0, 3.0])\n\na[:, np.newaxis] + b\n\narray([[ 1.,  2.,  3.],\n       [11., 12., 13.],\n       [21., 22., 23.],\n       [31., 32., 33.]])\n\n\n\nfrom numpy import array, argmin, sqrt, sum\nobservation = array([111.0, 188.0])\n\ncodes = array([[102.0, 203.0],\n\n               [132.0, 193.0],\n\n               [45.0, 155.0],\n\n               [57.0, 173.0]])\n\ndiff = codes - observation    # the broadcast happens here\n\ndist = sqrt(sum(diff**2,axis=-1))\n\nargmin(dist)\n\n0"
  },
  {
    "objectID": "numpy.html#copies-and-views",
    "href": "numpy.html#copies-and-views",
    "title": "Numpy",
    "section": "Copies and views",
    "text": "Copies and views\n\nIndexing operations\n\nx = np.arange(10)\n\nx\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n\ny = x[1:3]  # creates a view\n\ny\n\narray([1, 2])\n\n\n\nx[1:3] = [10, 11]\nx\n\narray([ 0, 10, 11,  3,  4,  5,  6,  7,  8,  9])\n\n\n\ny\n\narray([10, 11])\n\n\n\nx = np.arange(9).reshape(3, 3)\nx\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\ny = x[[1, 2]]\ny\n\narray([[3, 4, 5],\n       [6, 7, 8]])\n\n\n\ny.base is None\n\nTrue\n\n\n\nx[[1, 2]] = [[10, 11, 12], [13, 14, 15]]\nx\n\narray([[ 0,  1,  2],\n       [10, 11, 12],\n       [13, 14, 15]])\n\n\n\ny\n\narray([[3, 4, 5],\n       [6, 7, 8]])\n\n\n\nx = np.ones((2, 3))\n\ny = x.T  # makes the array non-contiguous\n\ny\n\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.]])\n\n\n\nHow to tell if the array is a view or a copy\n\nx = np.arange(9)\n\nx\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8])\n\n\n\ny = x.reshape(3, 3)\n\ny\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\ny.base  # .reshape() creates a view\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8])\n\n\n\nz = y[[2, 1]]\nz\n\narray([[6, 7, 8],\n       [3, 4, 5]])\n\n\n\nz.base is None  # advanced indexing creates a copy\n\nTrue"
  },
  {
    "objectID": "numpy.html#structured-arrays",
    "href": "numpy.html#structured-arrays",
    "title": "Numpy",
    "section": "Structured arrays",
    "text": "Structured arrays\n\nx = np.array([('Rex', 9, 81.0), ('Fido', 3, 27.0)],\n             dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])\nx\n\narray([('Rex', 9, 81.), ('Fido', 3, 27.)],\n      dtype=[('name', '&lt;U10'), ('age', '&lt;i4'), ('weight', '&lt;f4')])\n\n\n\nx[1]\n\n('Fido', 3, 27.)\n\n\n\nx['age']\n\narray([9, 3], dtype=int32)\n\n\n\nx['age'] = 5\n\n\nx\n\narray([('Rex', 5, 81.), ('Fido', 5, 27.)],\n      dtype=[('name', '&lt;U10'), ('age', '&lt;i4'), ('weight', '&lt;f4')])\n\n\n\nnp.dtype([('x', 'f4'), ('y', np.float32), ('z', 'f4', (2, 2))])\n\ndtype([('x', '&lt;f4'), ('y', '&lt;f4'), ('z', '&lt;f4', (2, 2))])\n\n\n\nnp.dtype([('x', 'f4'), ('', 'i4'), ('z', 'i8')])\n\ndtype([('x', '&lt;f4'), ('f1', '&lt;i4'), ('z', '&lt;i8')])\n\n\n\nnp.dtype('i8, f4, S3')\n\ndtype([('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', 'S3')])\n\n\n\nnp.dtype('3int8, float32, (2, 3)float64')\n\ndtype([('f0', 'i1', (3,)), ('f1', '&lt;f4'), ('f2', '&lt;f8', (2, 3))])\n\n\n\nnp.dtype({'names': ['col1', 'col2'], 'formats': ['i4', 'f4']})\n\ndtype([('col1', '&lt;i4'), ('col2', '&lt;f4')])\n\n\n\nnp.dtype({'names': ['col1', 'col2'],\n          'formats': ['i4', 'f4'],\n          'offsets': [0, 4],\n          'itemsize': 12})\n\ndtype({'names': ['col1', 'col2'], 'formats': ['&lt;i4', '&lt;f4'], 'offsets': [0, 4], 'itemsize': 12})\n\n\n\nnp.dtype({'col1': ('i1', 0), 'col2': ('f4', 1)})\n\ndtype([('col1', 'i1'), ('col2', '&lt;f4')])\n\n\n\nManipulating and Displaying Structured Datatypes\n\nd = np.dtype([('x', 'i8'), ('y', 'f4')])\n\nd.names\n\n('x', 'y')\n\n\n\nd['x']\n\ndtype('int64')\n\n\n\nd.fields\n\nmappingproxy({'x': (dtype('int64'), 0), 'y': (dtype('float32'), 8)})\n\n\n\ndef print_offsets(d):\n\n    print(\"offsets:\", [d.fields[name][1] for name in d.names])\n\n    print(\"itemsize:\", d.itemsize)\n\n\nprint_offsets(np.dtype('u1, u1, i4, u1, i8, u2'))\n\noffsets: [0, 1, 2, 6, 7, 15]\nitemsize: 17\n\n\n\nprint_offsets(np.dtype('u1, u1, i4, u1, i8, u2', align=True))\n\noffsets: [0, 1, 4, 8, 16, 24]\nitemsize: 32\n\n\n\nnp.dtype([(('my title', 'name'), 'f4')])\n\ndtype([(('my title', 'name'), '&lt;f4')])\n\n\n\nnp.dtype({'name': ('i4', 0, 'my title')})\n\ndtype([(('my title', 'name'), '&lt;i4')])\n\n\n\nfor name in d.names:\n    print(d.fields[name][:2])\n\n(dtype('int64'), 0)\n(dtype('float32'), 8)\n\n\n\n\nIndexing and Assignment to Structured arrays\n\nx = np.array([(1, 2, 3), (4, 5, 6)], dtype='i8, f4, f8')\nx\n\narray([(1, 2., 3.), (4, 5., 6.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '&lt;f8')])\n\n\n\nx[1] = (7, 8, 9)\n\n\nx\n\narray([(1, 2., 3.), (7, 8., 9.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '&lt;f8')])\n\n\n\nx = np.zeros(2, dtype='i8, f4, ?, S1')\nx[:] = 3\nx\n\narray([(3, 3.,  True, b'3'), (3, 3.,  True, b'3')],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '?'), ('f3', 'S1')])\n\n\n\nx[:] = np.arange(2)\nx\n\narray([(0, 0., False, b'0'), (1, 1.,  True, b'1')],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f4'), ('f2', '?'), ('f3', 'S1')])\n\n\n\na = np.zeros(3, dtype=[('a', 'i8'), ('b', 'f4'), ('c', 'S3')])\nb = np.ones(3, dtype=[('x', 'f4'), ('y', 'S3'), ('z', 'O')])\nb[:] = a\nb\n\narray([(0., b'0.0', b''), (0., b'0.0', b''), (0., b'0.0', b'')],\n      dtype=[('x', '&lt;f4'), ('y', 'S3'), ('z', 'O')])\n\n\n\nx = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])\n\nx['foo']\n\narray([1, 3])\n\n\n\nx['foo'] = 10\n\nx\n\narray([(10, 2.), (10, 4.)], dtype=[('foo', '&lt;i8'), ('bar', '&lt;f4')])\n\n\n\ny = x['bar']\n\ny[:] = 11\n\nx\n\narray([(10, 11.), (10, 11.)], dtype=[('foo', '&lt;i8'), ('bar', '&lt;f4')])\n\n\n\ny.dtype, y.shape, y.strides\n\n(dtype('float32'), (2,), (12,))\n\n\n\nx = np.zeros((2, 2), dtype=[('a', np.int32), ('b', np.float64, (3, 3))])\n\nx['a'].shape\n\n(2, 2)\n\n\n\nx['b'].shape\n\n(2, 2, 3, 3)\n\n\n\na = np.zeros(3, dtype=[('a', 'i4'), ('b', 'i4'), ('c', 'f4')])\n\na[['a', 'c']]\n\narray([(0, 0.), (0, 0.), (0, 0.)],\n      dtype={'names': ['a', 'c'], 'formats': ['&lt;i4', '&lt;f4'], 'offsets': [0, 8], 'itemsize': 12})\n\n\n\nfrom numpy.lib.recfunctions import repack_fields\n\nrepack_fields(a[['a', 'c']]).view('i8')  # supported in 1.16\n\narray([0, 0, 0])\n\n\n\nb = np.zeros(3, dtype=[('x', 'f4'), ('y', 'f4'), ('z', 'f4')])\n\nb[['x', 'z']].view('f4')\n\narray([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)\n\n\n\nfrom numpy.lib.recfunctions import structured_to_unstructured\n\nstructured_to_unstructured(b[['x', 'z']])\n\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.]], dtype=float32)\n\n\n\na[['a', 'c']] = (2, 3)\n\na\n\narray([(2, 0, 3.), (2, 0, 3.), (2, 0, 3.)],\n      dtype=[('a', '&lt;i4'), ('b', '&lt;i4'), ('c', '&lt;f4')])\n\n\n\na[['a', 'c']] = a[['c', 'a']]\n\n\nx = np.array([(1, 2., 3.)], dtype='i, f, f')\n\nscalar = x[0]\n\nscalar\n\n(1, 2., 3.)\n\n\n\ntype(scalar)\n\nnumpy.void\n\n\n\nx = np.array([(1, 2), (3, 4)], dtype=[('foo', 'i8'), ('bar', 'f4')])\ns = x[0]\ns['bar'] = 100\nx\n\narray([(1, 100.), (3,   4.)], dtype=[('foo', '&lt;i8'), ('bar', '&lt;f4')])\n\n\n\nscalar = np.array([(1, 2., 3.)], dtype='i, f, f')[0]\nscalar[0]\n\n1\n\n\n\nscalar[1] = 4\n\n\nscalar.item(), type(scalar.item())\n\n((1, 4.0, 3.0), tuple)\n\n\n\nStructure Comparison and Promotiona\n\na = np.array([(1, 1), (2, 2)], dtype=[('a', 'i4'), ('b', 'i4')])\n\nb = np.array([(1, 1), (2, 3)], dtype=[('a', 'i4'), ('b', 'i4')])\n\na == b\n\narray([ True, False])\n\n\n\na = np.array([(1, 1), (2, 2)], dtype=[('a', 'i4'), ('b', 'i4')])\n\nb = np.array([(1, 1), (2, 3)], dtype=[('a', 'i4'), ('b', 'i4')])\n\na == b\n\narray([ True, False])\n\n\n\nb = np.array([(1.0, 1), (2.5, 2)], dtype=[(\"a\", \"f4\"), (\"b\", \"i4\")])\n\na == b\n\narray([ True, False])\n\n\n\nnp.result_type(np.dtype(\"i,&gt;i\"))\n\ndtype([('f0', '&lt;i4'), ('f1', '&lt;i4')])\n\n\n\nnp.result_type(np.dtype(\"i,&gt;i\"), np.dtype(\"i,i\"))\n\ndtype([('f0', '&lt;i4'), ('f1', '&lt;i4')])\n\n\n\ndt = np.dtype(\"i1,V3,i4,V1\")[[\"f0\", \"f2\"]]\ndt\n\ndtype({'names': ['f0', 'f2'], 'formats': ['i1', '&lt;i4'], 'offsets': [0, 4], 'itemsize': 9})\n\n\n\nnp.result_type(dt)\n\ndtype([('f0', 'i1'), ('f2', '&lt;i4')])\n\n\n\ndt = np.dtype(\"i1,V3,i4,V1\", align=True)[[\"f0\", \"f2\"]]\n\ndt\n\ndtype({'names': ['f0', 'f2'], 'formats': ['i1', '&lt;i4'], 'offsets': [0, 4], 'itemsize': 12}, align=True)\n\n\n\nnp.result_type(dt)\n\ndtype([('f0', 'i1'), ('f2', '&lt;i4')], align=True)\n\n\n\nnp.result_type(dt).isalignedstruct\n\nTrue\n\n\n\nnp.result_type(np.dtype(\"i,i\"), np.dtype(\"i,i\", align=True))\n\ndtype([('f0', '&lt;i4'), ('f1', '&lt;i4')], align=True)\n\n\n\n\nRecord Arrays\n\nrecordarr = np.rec.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n\n                   dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'S10')])\n\n\nrecordarr.bar\n\narray([2., 3.], dtype=float32)\n\n\n\nrecordarr[1:2]\n\nrec.array([(2, 3., b'World')],\n          dtype=[('foo', '&lt;i4'), ('bar', '&lt;f4'), ('baz', 'S10')])\n\n\n\nrecordarr[1:2].foo\n\narray([2], dtype=int32)\n\n\n\nrecordarr.foo[1:2]\n\narray([2], dtype=int32)\n\n\n\nrecordarr[1].baz\n\nb'World'\n\n\n\narr = np.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n\n            dtype=[('foo', 'i4'), ('bar', 'f4'), ('baz', 'S10')])\n\n\nrecordarr = np.rec.array(arr)\n\n\narr = np.array([(1, 2., 'Hello'), (2, 3., \"World\")],\n\n               dtype=[('foo', 'i4'),('bar', 'f4'), ('baz', 'a10')])\n\n\nrecordarr = arr.view(dtype=np.dtype((np.record, arr.dtype)),\n\n                     type=np.recarray)\n\n\nrecordarr = arr.view(np.recarray)\n\nrecordarr.dtype\n\ndtype((numpy.record, [('foo', '&lt;i4'), ('bar', '&lt;f4'), ('baz', 'S10')]))\n\n\n\narr2 = recordarr.view(recordarr.dtype.fields or recordarr.dtype, np.ndarray)\n\n\nrecordarr = np.rec.array([('Hello', (1, 2)), (\"World\", (3, 4))],\n\n                dtype=[('foo', 'S6'),('bar', [('A', int), ('B', int)])])\n\n\ntype(recordarr.foo)\n\nnumpy.ndarray\n\n\n\ntype(recordarr.bar)\n\nnumpy.recarray\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nb = np.array([(1, 2, 5), (4, 5, 7), (7, 8 ,11), (10, 11, 12)],\n\n             dtype=[('x', 'i4'), ('y', 'f4'), ('z', 'f8')])\n\n\nrfn.apply_along_fields(np.mean, b)\n\narray([ 2.66666667,  5.33333333,  8.66666667, 11.        ])\n\n\n\nrfn.apply_along_fields(np.mean, b[['x', 'z']])\n\narray([ 3. ,  5.5,  9. , 11. ])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.array([(1, (2, 3.0)), (4, (5, 6.0))],\n\n  dtype=[('a', np.int64), ('b', [('ba', np.double), ('bb', np.int64)])])\n\n\nrfn.drop_fields(a, 'a')\n\narray([((2., 3),), ((5., 6),)],\n      dtype=[('b', [('ba', '&lt;f8'), ('bb', '&lt;i8')])])\n\n\n\nrfn.drop_fields(a, 'ba')\n\narray([(1, (3,)), (4, (6,))], dtype=[('a', '&lt;i8'), ('b', [('bb', '&lt;i8')])])\n\n\n\nrfn.drop_fields(a, ['ba', 'bb'])\n\narray([(1,), (4,)], dtype=[('a', '&lt;i8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nndtype = [('a', int)]\n\na = np.ma.array([1, 1, 1, 2, 2, 3, 3],\n\n        mask=[0, 0, 1, 0, 0, 0, 1]).view(ndtype)\n\n\nrfn.find_duplicates(a, ignoremask=True, return_index=True)\n\n(masked_array(data=[(1,), (1,), (2,), (2,)],\n              mask=[(False,), (False,), (False,), (False,)],\n        fill_value=(999999,),\n             dtype=[('a', '&lt;i8')]),\n array([0, 1, 3, 4]))\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nndtype = np.dtype([('a', '&lt;i4'), ('b', [('ba', '&lt;f8'), ('bb', '&lt;i4')])])\n\nrfn.flatten_descr(ndtype)\n\n(('a', dtype('int32')), ('ba', dtype('float64')), ('bb', dtype('int32')))\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nndtype =  np.dtype([('A', int),\n\n                    ('B', [('BA', int),\n\n                           ('BB', [('BBA', int), ('BBB', int)])])])\n\nrfn.get_fieldstructure(ndtype)\n\n{'A': [],\n 'B': [],\n 'BA': ['B'],\n 'BB': ['B'],\n 'BBA': ['B', 'BB'],\n 'BBB': ['B', 'BB']}\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nrfn.get_names(np.empty((1,), dtype=[('A', int)]).dtype)\n\n('A',)\n\n\n\nrfn.get_names(np.empty((1,), dtype=[('A',int), ('B', float)]).dtype)\n\n('A', 'B')\n\n\n\nadtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])])\n\nrfn.get_names(adtype)\n\n('a', ('b', ('ba', 'bb')))\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nrfn.get_names_flat(np.empty((1,), dtype=[('A', int)]).dtype) is None\n\nFalse\n\n\n\nrfn.get_names_flat(np.empty((1,), dtype=[('A',int), ('B', str)]).dtype)\n\n('A', 'B')\n\n\n\nadtype = np.dtype([('a', int), ('b', [('ba', int), ('bb', int)])])\n\nrfn.get_names_flat(adtype)\n\n('a', 'b', 'ba', 'bb')\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nrfn.merge_arrays((np.array([1, 2]), np.array([10., 20., 30.])))\n\narray([( 1, 10.), ( 2, 20.), (-1, 30.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f8')])\n\n\n\nrfn.merge_arrays((np.array([1, 2], dtype=np.int64),\n\n        np.array([10., 20., 30.])), usemask=False)\n\narray([( 1, 10.), ( 2, 20.), (-1, 30.)],\n      dtype=[('f0', '&lt;i8'), ('f1', '&lt;f8')])\n\n\n\nrfn.merge_arrays((np.array([1, 2]).view([('a', np.int64)]),\n\n              np.array([10., 20., 30.])),\n\n             usemask=False, asrecarray=True)\n\nrec.array([( 1, 10.), ( 2, 20.), (-1, 30.)],\n          dtype=[('a', '&lt;i8'), ('f1', '&lt;f8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.array([(1, 10.), (2, 20.)], dtype=[('A', np.int64), ('B', np.float64)])\n\nb = np.zeros((3,), dtype=a.dtype)\n\nrfn.recursive_fill_fields(a, b)\n\narray([(1, 10.), (2, 20.), (0,  0.)], dtype=[('A', '&lt;i8'), ('B', '&lt;f8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.array([(1, (2, [3.0, 30.])), (4, (5, [6.0, 60.]))],\n\n  dtype=[('a', int),('b', [('ba', float), ('bb', (float, 2))])])\n\n\nrfn.rename_fields(a, {'a':'A', 'bb':'BB'})\n\narray([(1, (2., [ 3., 30.])), (4, (5., [ 6., 60.]))],\n      dtype=[('A', '&lt;i8'), ('b', [('ba', '&lt;f8'), ('BB', '&lt;f8', (2,))])])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\ndef print_offsets(d):\n\n    print(\"offsets:\", [d.fields[name][1] for name in d.names])\n\n    print(\"itemsize:\", d.itemsize)\n\n\ndt = np.dtype('u1, &lt;i8, &lt;f8', align=True)\n\ndt\n\ndtype([('f0', 'u1'), ('f1', '&lt;i8'), ('f2', '&lt;f8')], align=True)\n\n\n\nprint_offsets(dt)\n\noffsets: [0, 8, 16]\nitemsize: 24\n\n\n\npacked_dt = rfn.repack_fields(dt)\n\npacked_dt\n\ndtype([('f0', 'u1'), ('f1', '&lt;i8'), ('f2', '&lt;f8')])\n\n\n\nprint_offsets(packed_dt)\n\noffsets: [0, 1, 9]\nitemsize: 17\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.ones(4, dtype=[('a', 'i4'), ('b', 'f8'), ('c', 'u1')])\n\nrfn.require_fields(a, [('b', 'f4'), ('c', 'u1')])\n\narray([(1., 1), (1., 1), (1., 1), (1., 1)],\n      dtype=[('b', '&lt;f4'), ('c', 'u1')])\n\n\n\nrfn.require_fields(a, [('b', 'f4'), ('newf', 'u1')])\n\narray([(1., 0), (1., 0), (1., 0), (1., 0)],\n      dtype=[('b', '&lt;f4'), ('newf', 'u1')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\nx = np.array([1, 2,])\n\nrfn.stack_arrays(x) is x\n\nTrue\n\n\n\nz = np.array([('A', 1), ('B', 2)], dtype=[('A', '|S3'), ('B', float)])\n\nzz = np.array([('a', 10., 100.), ('b', 20., 200.), ('c', 30., 300.)],\n\n  dtype=[('A', '|S3'), ('B', np.double), ('C', np.double)])\n\ntest = rfn.stack_arrays((z,zz))\n\ntest\n\nmasked_array(data=[(b'A', 1.0, --), (b'B', 2.0, --), (b'a', 10.0, 100.0),\n                   (b'b', 20.0, 200.0), (b'c', 30.0, 300.0)],\n             mask=[(False, False,  True), (False, False,  True),\n                   (False, False, False), (False, False, False),\n                   (False, False, False)],\n       fill_value=(b'N/A', 1.e+20, 1.e+20),\n            dtype=[('A', 'S3'), ('B', '&lt;f8'), ('C', '&lt;f8')])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\na = np.zeros(4, dtype=[('a', 'i4'), ('b', 'f4,u2'), ('c', 'f4', 2)])\n\na\n\narray([(0, (0., 0), [0., 0.]), (0, (0., 0), [0., 0.]),\n       (0, (0., 0), [0., 0.]), (0, (0., 0), [0., 0.])],\n      dtype=[('a', '&lt;i4'), ('b', [('f0', '&lt;f4'), ('f1', '&lt;u2')]), ('c', '&lt;f4', (2,))])\n\n\n\nrfn.structured_to_unstructured(a)\n\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n\n\n\nb = np.array([(1, 2, 5), (4, 5, 7), (7, 8 ,11), (10, 11, 12)],\n\n             dtype=[('x', 'i4'), ('y', 'f4'), ('z', 'f8')])\n\n\nnp.mean(rfn.structured_to_unstructured(b[['x', 'z']]), axis=-1)\n\narray([ 3. ,  5.5,  9. , 11. ])\n\n\n\nfrom numpy.lib import recfunctions as rfn\n\ndt = np.dtype([('a', 'i4'), ('b', 'f4,u2'), ('c', 'f4', 2)])\n\na = np.arange(20).reshape((4,5))\n\na\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19]])\n\n\n\nrfn.unstructured_to_structured(a, dt)\n\narray([( 0, ( 1.,  2), [ 3.,  4.]), ( 5, ( 6.,  7), [ 8.,  9.]),\n       (10, (11., 12), [13., 14.]), (15, (16., 17), [18., 19.])],\n      dtype=[('a', '&lt;i4'), ('b', [('f0', '&lt;f4'), ('f1', '&lt;u2')]), ('c', '&lt;f4', (2,))])"
  },
  {
    "objectID": "numpy.html#universal-functions",
    "href": "numpy.html#universal-functions",
    "title": "Numpy",
    "section": "Universal functions",
    "text": "Universal functions\n\nnp.array([0,2,3,4]) + np.array([1,1,-1,2])\n\narray([1, 3, 2, 6])\n\n\n\nx = np.arange(9).reshape(3,3)\n\nx\n\narray([[0, 1, 2],\n       [3, 4, 5],\n       [6, 7, 8]])\n\n\n\nnp.add.reduce(x, 1)\n\narray([ 3, 12, 21])\n\n\n\nnp.add.reduce(x, (0, 1))\n\n36\n\n\n\nx.dtype\n\ndtype('int64')\n\n\n\nnp.multiply.reduce(x, dtype=float)\n\narray([ 0., 28., 80.])\n\n\n\ny = np.zeros(3, dtype=int)\n\ny\n\narray([0, 0, 0])\n\n\n\nnp.multiply.reduce(x, dtype=float, out=y)\n\narray([ 0, 28, 80])\n\n\n\nmark = {False: ' -', True: ' Y'}\n\ndef print_table(ntypes):\n\n    print('X ' + ' '.join(ntypes))\n\n    for row in ntypes:\n\n        print(row, end='')\n\n        for col in ntypes:\n\n            print(mark[np.can_cast(row, col)], end='')\n\n        print()\n\n\nprint_table(np.typecodes['All'])\n\nX ? b h i l q p B H I L Q P e f d g F D G S U V O M m\n? Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y\nb - Y Y Y Y Y Y - - - - - - Y Y Y Y Y Y Y Y Y Y Y - Y\nh - - Y Y Y Y Y - - - - - - - Y Y Y Y Y Y Y Y Y Y - Y\ni - - - Y Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\nl - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\nq - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\np - - - - Y Y Y - - - - - - - - Y Y - Y Y Y Y Y Y - Y\nB - - Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y Y - Y\nH - - - Y Y Y Y - Y Y Y Y Y - Y Y Y Y Y Y Y Y Y Y - Y\nI - - - - Y Y Y - - Y Y Y Y - - Y Y - Y Y Y Y Y Y - Y\nL - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\nQ - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\nP - - - - - - - - - - Y Y Y - - Y Y - Y Y Y Y Y Y - -\ne - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y Y - -\nf - - - - - - - - - - - - - - Y Y Y Y Y Y Y Y Y Y - -\nd - - - - - - - - - - - - - - - Y Y - Y Y Y Y Y Y - -\ng - - - - - - - - - - - - - - - - Y - - Y Y Y Y Y - -\nF - - - - - - - - - - - - - - - - - Y Y Y Y Y Y Y - -\nD - - - - - - - - - - - - - - - - - - Y Y Y Y Y Y - -\nG - - - - - - - - - - - - - - - - - - - Y Y Y Y Y - -\nS - - - - - - - - - - - - - - - - - - - - Y Y Y Y - -\nU - - - - - - - - - - - - - - - - - - - - - Y Y Y - -\nV - - - - - - - - - - - - - - - - - - - - - - Y Y - -\nO - - - - - - - - - - - - - - - - - - - - - - - Y - -\nM - - - - - - - - - - - - - - - - - - - - - - Y Y Y -\nm - - - - - - - - - - - - - - - - - - - - - - Y Y - Y"
  },
  {
    "objectID": "tmux.html",
    "href": "tmux.html",
    "title": "Tmux",
    "section": "",
    "text": "tmux\ntmux new\ntmux new -s &lt;session name&gt;\n\n\n\ntmux ls\ntmux list-sessions\ntmux new -s &lt;session name&gt;\n\n\n\ntmux a\ntmux at\ntmux a -t &lt;session name&gt;\n\n\n\ntmux kill-session -t &lt;session name&gt;\n\n\n\nCtrl + b $\n\n\n\nCtrl + b d\n\n\n\nCtrl + b w\n\n\n\nCtrl + b (\n\n\n\nCtrl + b )"
  },
  {
    "objectID": "tmux.html#session",
    "href": "tmux.html#session",
    "title": "Tmux",
    "section": "",
    "text": "tmux\ntmux new\ntmux new -s &lt;session name&gt;\n\n\n\ntmux ls\ntmux list-sessions\ntmux new -s &lt;session name&gt;\n\n\n\ntmux a\ntmux at\ntmux a -t &lt;session name&gt;\n\n\n\ntmux kill-session -t &lt;session name&gt;\n\n\n\nCtrl + b $\n\n\n\nCtrl + b d\n\n\n\nCtrl + b w\n\n\n\nCtrl + b (\n\n\n\nCtrl + b )"
  },
  {
    "objectID": "tmux.html#windows",
    "href": "tmux.html#windows",
    "title": "Tmux",
    "section": "Windows",
    "text": "Windows\n\nCreate session with named window\ntmux new -s mysession -n mywindow\n\n\nCreate new window\nCtrl + b c\n\n\nRename current window\nCtrl + b ,\n\n\nClose current window\nCtrl + b &\n\n\nList window\nCtrl + b w\n\n\nPrevious window\nCtrl + b p\n\n\nNext window\nCtrl + b n\n\n\nSwitch to window by number\nCtrl + b 0...9"
  },
  {
    "objectID": "tmux.html#panes",
    "href": "tmux.html#panes",
    "title": "Tmux",
    "section": "Panes",
    "text": "Panes\n\nSplit window vertically\nCtrl + b %\n\n\nSplit window horizontally\nCtrl + b \"\n\n\nNavigate panes\nCtrl + b up, down, right, left\n\n\nClose current pane\nCtrl + b x\n\n\nMove the current pane left\nCtrl + b {\n\n\nMove the current pane right\nCtrl + b }\n\n\nSwitch to next pane\nCtrl + b o\n\n\nShow pane numbers\nCtrl + b q 0...9\n\n\nConvert pane to window\nCtrl + b !\n\n\nToggle pane zoom\nCtrl + b z\n\n\nResize pane\nCtrl + b + up, down, right, left"
  },
  {
    "objectID": "python class.html",
    "href": "python class.html",
    "title": "Python Class",
    "section": "",
    "text": "Special methods you should probably know about (see data model link above) are:\n\n__getitem__\n__getattr__\n__setattr__\n__del__\n__init__\n__new__\n__enter__\n__exit__\n__len__\n__repr__\n__str__\n__iter__\n__call__\n\n\n\n\n Back to top"
  },
  {
    "objectID": "matplotlib.html",
    "href": "matplotlib.html",
    "title": "Matplotlib",
    "section": "",
    "text": "!pip list | grep matplotlib\n\nmatplotlib                    3.7.2\nmatplotlib-inline             0.1.6"
  },
  {
    "objectID": "matplotlib.html#setup",
    "href": "matplotlib.html#setup",
    "title": "Matplotlib",
    "section": "Setup",
    "text": "Setup\n\nimport matplotlib.pyplot as plt\n\n\nimport matplotlib\nprint(matplotlib.__version__)\n\n3.7.2"
  },
  {
    "objectID": "matplotlib.html#basic-plotting",
    "href": "matplotlib.html#basic-plotting",
    "title": "Matplotlib",
    "section": "Basic Plotting",
    "text": "Basic Plotting\n\nplt.plot([1,2,3,4], [1,4,9,16]) #line plot\nplt.scatter([1,2,3,4], [1,5,10,16]) #scatter plot\nplt.bar([1,2,3,4], [1,5,10,16]) #bar plot\n\n&lt;BarContainer object of 4 artists&gt;\n\n\n\n\n\n\nplt.hist([1,2,3,4], [1,5,10,16]) #scatter plot\n\n(array([4., 0., 0.]),\n array([ 1.,  5., 10., 16.]),\n &lt;BarContainer object of 3 artists&gt;)"
  },
  {
    "objectID": "matplotlib.html#figures-and-axes",
    "href": "matplotlib.html#figures-and-axes",
    "title": "Matplotlib",
    "section": "Figures and Axes",
    "text": "Figures and Axes\n\nfig, ax = plt.subplots()\nax.set_ylim([0,2])\n\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_title('Title')\n\nText(0.5, 1.0, 'Title')"
  },
  {
    "objectID": "matplotlib.html#customizing-plots",
    "href": "matplotlib.html#customizing-plots",
    "title": "Matplotlib",
    "section": "Customizing Plots",
    "text": "Customizing Plots\n\nplt.plot([1, 2, 3, 4], [1, 4, 9, 16],\n         linestyle = '--',\n         color = 'r')\nplt.grid(True)\nplt.xlim(0, 5)\nplt.ylim(0, 20)\n\n(0.0, 20.0)"
  },
  {
    "objectID": "matplotlib.html#multiple-plots",
    "href": "matplotlib.html#multiple-plots",
    "title": "Matplotlib",
    "section": "Multiple Plots",
    "text": "Multiple Plots\n\nfig, ax = plt.subplots(2, \n                      sharex = True,\n                      sharey = True)\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.axes_grid1 import Divider\nimport mpl_toolkits.axes_grid1.axes_size as Size\n\nfig = plt.figure(figsize=(5.5, 4))\n\n# the rect parameter will be ignored as we will set axes_locator\nrect = (0.1, 0.1, 0.8, 0.8)\nax = [fig.add_axes(rect, label=\"%d\" % i) for i in range(4)]\n\n\nhoriz = [Size.AxesX(ax[0]), Size.Fixed(.5), Size.AxesX(ax[1])]\nvert = [Size.AxesY(ax[0]), Size.Fixed(.5), Size.AxesY(ax[2])]\n\n# divide the axes rectangle into grid whose size is specified by horiz * vert\ndivider = Divider(fig, rect, horiz, vert, aspect=False)\n\n\nax[0].set_axes_locator(divider.new_locator(nx=0, ny=0))\nax[1].set_axes_locator(divider.new_locator(nx=2, ny=0))\nax[2].set_axes_locator(divider.new_locator(nx=0, ny=2))\nax[3].set_axes_locator(divider.new_locator(nx=2, ny=2))\n\nax[0].set_xlim(0, 2)\nax[1].set_xlim(0, 1)\n\nax[0].set_ylim(0, 1)\nax[2].set_ylim(0, 2)\n\ndivider.set_aspect(1.)\n\nfor ax1 in ax:\n    ax1.tick_params(labelbottom=False, labelleft=False)\n\nplt.show()\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nim1 = np.arange(100).reshape((10, 10))\nim2 = im1.T\nim3 = np.flipud(im1)\nim4 = np.fliplr(im2)\n\nfig = plt.figure(figsize=(4., 4.))\ngrid = ImageGrid(fig, 111,  # similar to subplot(111)\n                 nrows_ncols=(2, 2),  # creates 2x2 grid of axes\n                 axes_pad=0.1,  # pad between axes in inch.\n                 )\n\nfor ax, im in zip(grid, [im1, im2, im3, im4]):\n    # Iterating over the grid returns the Axes.\n    ax.imshow(im)\n\nplt.show()"
  },
  {
    "objectID": "matplotlib.html#text-and-annotations",
    "href": "matplotlib.html#text-and-annotations",
    "title": "Matplotlib",
    "section": "Text and Annotations",
    "text": "Text and Annotations\n\nplt.text(0.5, 0.5, 'Hello')\n\nText(0.5, 0.5, 'Hello')\n\n\n\n\n\n\narrowprops=dict(facecolor='black', shrink=0.05)\n\nplt.annotate('Hello', xy=(0.5, 0.5),\n             xytext=(0.6, 0.6),\n             arrowprops=arrowprops)\n\nText(0.6, 0.6, 'Hello')"
  },
  {
    "objectID": "matplotlib.html#saving-figures",
    "href": "matplotlib.html#saving-figures",
    "title": "Matplotlib",
    "section": "Saving Figures",
    "text": "Saving Figures\n\nplt.savefig('Data/test_figure.svg')\n\n&lt;Figure size 640x480 with 0 Axes&gt;"
  },
  {
    "objectID": "matplotlib.html#animation",
    "href": "matplotlib.html#animation",
    "title": "Matplotlib",
    "section": "Animation",
    "text": "Animation\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport matplotlib.animation as animation\nfrom matplotlib.patches import ConnectionPatch\nfrom IPython.display import HTML\n\nfig, (axl, axr) = plt.subplots(\n    ncols=2,\n    sharey=True,\n    figsize=(6, 2),\n    gridspec_kw=dict(width_ratios=[1, 3], wspace=0),\n)\naxl.set_aspect(1)\naxr.set_box_aspect(1 / 3)\naxr.yaxis.set_visible(False)\naxr.xaxis.set_ticks([0, np.pi, 2 * np.pi], [\"0\", r\"$\\pi$\", r\"$2\\pi$\"])\n\n# draw circle with initial point in left Axes\nx = np.linspace(0, 2 * np.pi, 50)\naxl.plot(np.cos(x), np.sin(x), \"k\", lw=0.3)\npoint, = axl.plot(0, 0, \"o\")\n\n# draw full curve to set view limits in right Axes\nsine, = axr.plot(x, np.sin(x))\n\n# draw connecting line between both graphs\ncon = ConnectionPatch(\n    (1, 0),\n    (0, 0),\n    \"data\",\n    \"data\",\n    axesA=axl,\n    axesB=axr,\n    color=\"C0\",\n    ls=\"dotted\",\n)\nfig.add_artist(con)\n\n\ndef animate(i):\n    x = np.linspace(0, i, int(i * 25 / np.pi))\n    sine.set_data(x, np.sin(x))\n    x, y = np.cos(i), np.sin(i)\n    point.set_data([x], [y])\n    con.xy1 = x, y\n    con.xy2 = i, y\n    return point, sine, con\n\nplt.close()\n\nani = animation.FuncAnimation(\n    fig,\n    animate,\n    interval=50,\n    blit=False,  # blitting can't be used with Figure artists\n    frames=x,\n    repeat_delay=100,\n)\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport matplotlib.animation as animation\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\ndef random_walk(num_steps, max_step=0.05):\n    \"\"\"Return a 3D random walk as (num_steps, 3) array.\"\"\"\n    start_pos = np.random.random(3)\n    steps = np.random.uniform(-max_step, max_step, size=(num_steps, 3))\n    walk = start_pos + np.cumsum(steps, axis=0)\n    return walk\n\n\ndef update_lines(num, walks, lines):\n    for line, walk in zip(lines, walks):\n        # NOTE: there is no .set_data() for 3 dim data...\n        line.set_data(walk[:num, :2].T)\n        line.set_3d_properties(walk[:num, 2])\n    return lines\n\n\n# Data: 40 random walks as (num_steps, 3) arrays\nnum_steps = 10\nwalks = [random_walk(num_steps) for index in range(15)]\n\n# Attaching 3D axis to the figure\nfig = plt.figure()\nax = fig.add_subplot(projection=\"3d\")\n\n# Create lines initially without data\nlines = [ax.plot([], [], [])[0] for _ in walks]\n\n# Setting the axes properties\nax.set(xlim3d=(0, 1), xlabel='X')\nax.set(ylim3d=(0, 1), ylabel='Y')\nax.set(zlim3d=(0, 1), zlabel='Z')\n\nplt.close()\n\n# Creating the Animation object\nani = animation.FuncAnimation(\n    fig, update_lines, num_steps, fargs=(walks, lines), interval=100)\n\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "matplotlib.html#d-plots",
    "href": "matplotlib.html#d-plots",
    "title": "Matplotlib",
    "section": "3D plots",
    "text": "3D plots\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib import cbook, cm\nfrom matplotlib.colors import LightSource\n\n# Load and format data\ndem = cbook.get_sample_data('jacksboro_fault_dem.npz', np_load = True)\n\nz = dem['elevation']\nnrows, ncols = z.shape\nx = np.linspace(dem['xmin'], dem['xmax'], ncols)\ny = np.linspace(dem['ymin'], dem['ymax'], nrows)\nx, y = np.meshgrid(x, y)\n\nregion = np.s_[5:50, 5:50]\nx, y, z = x[region], y[region], z[region]\n\n# Set up plot\nfig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n\nls = LightSource(270, 45)\n# To use a custom hillshading mode, override the built-in shading and pass\n# in the rgb colors of the shaded surface calculated from \"shade\".\nrgb = ls.shade(z, cmap=cm.gist_earth, vert_exag=0.1, blend_mode='soft')\nsurf = ax.plot_surface(x, y, z, rstride=1, cstride=1, facecolors=rgb,\n                       linewidth=0, antialiased=False, shade=False)\n\nplt.show()\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nfrom mpl_toolkits.mplot3d import axes3d\n\nax = plt.figure().add_subplot(projection='3d')\nX, Y, Z = axes3d.get_test_data(0.05)\n\n# Plot the 3D surface\nax.plot_surface(X, Y, Z, edgecolor='royalblue', lw=0.5, rstride=8, cstride=8,\n                alpha=0.3)\n\n# Plot projections of the contours for each dimension.  By choosing offsets\n# that match the appropriate axes limits, the projected contours will sit on\n# the 'walls' of the graph\nax.contourf(X, Y, Z, zdir='z', offset=-100, cmap='coolwarm')\nax.contourf(X, Y, Z, zdir='x', offset=-40, cmap='coolwarm')\nax.contourf(X, Y, Z, zdir='y', offset=40, cmap='coolwarm')\n\nax.set(xlim=(-40, 40), ylim=(-40, 40), zlim=(-100, 100),\n       xlabel='X', ylabel='Y', zlabel='Z')\n\nplt.show()\n\n\n\n\n\nimport math\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom matplotlib.collections import PolyCollection\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\ndef polygon_under_graph(x, y):\n    \"\"\"\n    Construct the vertex list which defines the polygon filling the space under\n    the (x, y) line graph. This assumes x is in ascending order.\n    \"\"\"\n    return [(x[0], 0.), *zip(x, y), (x[-1], 0.)]\n\n\nax = plt.figure().add_subplot(projection='3d')\n\nx = np.linspace(0., 10., 31)\nlambdas = range(1, 9)\n\n# verts[i] is a list of (x, y) pairs defining polygon i.\ngamma = np.vectorize(math.gamma)\nverts = [polygon_under_graph(x, l**x * np.exp(-l) / gamma(x + 1))\n         for l in lambdas]\nfacecolors = plt.colormaps['viridis_r'](np.linspace(0, 1, len(verts)))\n\npoly = PolyCollection(verts, facecolors=facecolors, alpha=.7)\nax.add_collection3d(poly, zs=lambdas, zdir='y')\n\nax.set(xlim=(0, 10), ylim=(1, 9), zlim=(0, 0.35),\n       xlabel='x', ylabel=r'$\\lambda$', zlabel='probability')\n\nplt.show()\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Fixing random state for reproducibility\nnp.random.seed(19680801)\n\n\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\n\ncolors = ['r', 'g', 'b', 'y']\nyticks = [3, 2, 1, 0]\nfor c, k in zip(colors, yticks):\n    # Generate the random data for the y=k 'layer'.\n    xs = np.arange(20)\n    ys = np.random.rand(20)\n\n    # You can provide either a single color or an array with the same length as\n    # xs and ys. To demonstrate this, we color the first bar of each set cyan.\n    cs = [c] * len(xs)\n    cs[0] = 'c'\n\n    # Plot the bar graph given by xs and ys on the plane y=k with 80% opacity.\n    ax.bar(xs, ys, zs=k, zdir='y', color=cs, alpha=0.8)\n\nax.set_xlabel('X')\nax.set_ylabel('Y')\nax.set_zlabel('Z')\n\n# On the y-axis let's only label the discrete values that we have data for.\nax.set_yticks(yticks)\n\nplt.show()"
  },
  {
    "objectID": "pivottablesjs.html",
    "href": "pivottablesjs.html",
    "title": "Pivot Tables js",
    "section": "",
    "text": "import pandas as pd\nfrom pivottablejs import pivot_ui\nimport ipypivot as pt\n\ndf = pd.read_csv('Data/salaries.csv')\ndf.head()\n\n\n\n\n\n\n\n\ncompany\njob\ndegree\nsalary_more_then_100k\n\n\n\n\n0\ngoogle\nsales executive\nbachelors\n0\n\n\n1\ngoogle\nsales executive\nmasters\n0\n\n\n2\ngoogle\nbusiness manager\nbachelors\n1\n\n\n3\ngoogle\nbusiness manager\nmasters\n1\n\n\n4\ngoogle\ncomputer programmer\nbachelors\n0\n\n\n\n\n\n\n\n\npivot_ui(df)\n\n\n\n        \n        \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "pandas.html",
    "href": "pandas.html",
    "title": "Pandas",
    "section": "",
    "text": "import pandas as pd\n\n# Create an empty DataFrame\nempty_df = pd.DataFrame()"
  },
  {
    "objectID": "pandas.html#add-column",
    "href": "pandas.html#add-column",
    "title": "Pandas",
    "section": "",
    "text": "import pandas as pd\n\n# Create an empty DataFrame\nempty_df = pd.DataFrame()"
  },
  {
    "objectID": "pandas.html#edit-column-name",
    "href": "pandas.html#edit-column-name",
    "title": "Pandas",
    "section": "Edit Column name",
    "text": "Edit Column name\ndf_plot.rename(columns={'y': 'final'}, inplace=True)"
  },
  {
    "objectID": "pandas.html#drop-column",
    "href": "pandas.html#drop-column",
    "title": "Pandas",
    "section": "Drop Column",
    "text": "Drop Column\ncv_df.drop('cutoff', axis=1, inplace=True)"
  },
  {
    "objectID": "pandas.html#plots",
    "href": "pandas.html#plots",
    "title": "Pandas",
    "section": "Plots",
    "text": "Plots\n(\n    wide_df[['y']].plot(title='Production')\n)"
  },
  {
    "objectID": "pandas.html#long-form-to-wide-form",
    "href": "pandas.html#long-form-to-wide-form",
    "title": "Pandas",
    "section": "Long form to Wide form",
    "text": "Long form to Wide form\ndef long_form(df_plot):\n    return df_plot.melt('ds', var_name='unique_id', value_name='y')"
  },
  {
    "objectID": "pandas.html#wide-form-to-long-form",
    "href": "pandas.html#wide-form-to-long-form",
    "title": "Pandas",
    "section": "Wide form to long form",
    "text": "Wide form to long form\n#|eval: false\nwide_df = result.pivot(index='_time', columns='sensor', values='_value')\n# Reset the index to make 'id' a regular column\nwide_df.reset_index(inplace=True)\n\nwide_df.columns"
  },
  {
    "objectID": "pandas.html#aggregate",
    "href": "pandas.html#aggregate",
    "title": "Pandas",
    "section": "Aggregate",
    "text": "Aggregate\n\nto do"
  },
  {
    "objectID": "pandas.html#stats",
    "href": "pandas.html#stats",
    "title": "Pandas",
    "section": "Stats",
    "text": "Stats\n\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n# Load the dataset\nflights = (sns.load_dataset(\"flights\"))\nflights\n\n\n\n\n\n\n\n\nyear\nmonth\npassengers\n\n\n\n\n0\n1949\nJan\n112\n\n\n1\n1949\nFeb\n118\n\n\n2\n1949\nMar\n132\n\n\n3\n1949\nApr\n129\n\n\n4\n1949\nMay\n121\n\n\n...\n...\n...\n...\n\n\n139\n1960\nAug\n606\n\n\n140\n1960\nSep\n508\n\n\n141\n1960\nOct\n461\n\n\n142\n1960\nNov\n390\n\n\n143\n1960\nDec\n432\n\n\n\n\n144 rows × 3 columns\n\n\n\n\nflights.head(), flights.tail()\n\n(   year month  passengers\n 0  1949   Jan         112\n 1  1949   Feb         118\n 2  1949   Mar         132\n 3  1949   Apr         129\n 4  1949   May         121,\n      year month  passengers\n 139  1960   Aug         606\n 140  1960   Sep         508\n 141  1960   Oct         461\n 142  1960   Nov         390\n 143  1960   Dec         432)\n\n\n\nflights.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 144 entries, 0 to 143\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype   \n---  ------      --------------  -----   \n 0   year        144 non-null    int64   \n 1   month       144 non-null    category\n 2   passengers  144 non-null    int64   \ndtypes: category(1), int64(2)\nmemory usage: 2.9 KB\n\n\n\nflights.describe()\n\n\n\n\n\n\n\n\nyear\npassengers\n\n\n\n\ncount\n144.000000\n144.000000\n\n\nmean\n1954.500000\n280.298611\n\n\nstd\n3.464102\n119.966317\n\n\nmin\n1949.000000\n104.000000\n\n\n25%\n1951.750000\n180.000000\n\n\n50%\n1954.500000\n265.500000\n\n\n75%\n1957.250000\n360.500000\n\n\nmax\n1960.000000\n622.000000\n\n\n\n\n\n\n\n\nflights.describe(include = \"category\")\n\n\n\n\n\n\n\n\nmonth\n\n\n\n\ncount\n144\n\n\nunique\n12\n\n\ntop\nJan\n\n\nfreq\n12\n\n\n\n\n\n\n\n\nflights.year.head(), flights['year'].head(), flights[['year', 'passengers']].head()\n\n(0    1949\n 1    1949\n 2    1949\n 3    1949\n 4    1949\n Name: year, dtype: int64,\n 0    1949\n 1    1949\n 2    1949\n 3    1949\n 4    1949\n Name: year, dtype: int64,\n    year  passengers\n 0  1949         112\n 1  1949         118\n 2  1949         132\n 3  1949         129\n 4  1949         121)\n\n\n\nflights.iloc[1]\n\nyear          1949\nmonth          Feb\npassengers     118\nName: 1, dtype: object\n\n\n\nflights.loc[1, 'year']\n\n1949\n\n\n\n# Convert month names to datetime format with the given year\nflights['date'] = flights.apply(lambda row: pd.to_datetime(f\"{row['year']}-{row['month']}-01\"), axis=1)\nflights.set_index('date', inplace=True)\n\n# Drop redundant columns and rename the passengers column for clarity\nflights.drop(['year', 'month'], axis=1, inplace=True)\nflights.rename(columns={'passengers': 'Passengers'}, inplace=True)\n\n# Plot the data\nflights.plot(title=\"Monthly Air Passengers\", figsize=(12,6))\nplt.show()\n\n\n\n\n\ndf = flights\ndf.head()\n\n\n\n\n\n\n\n\nPassengers\n\n\ndate\n\n\n\n\n\n1949-01-01\n112\n\n\n1949-02-01\n118\n\n\n1949-03-01\n132\n\n\n1949-04-01\n129\n\n\n1949-05-01\n121\n\n\n\n\n\n\n\n\ndf.columns\n\nIndex(['Passengers'], dtype='object')\n\n\n\ndf.index\n\nDatetimeIndex(['1949-01-01', '1949-02-01', '1949-03-01', '1949-04-01',\n               '1949-05-01', '1949-06-01', '1949-07-01', '1949-08-01',\n               '1949-09-01', '1949-10-01',\n               ...\n               '1960-03-01', '1960-04-01', '1960-05-01', '1960-06-01',\n               '1960-07-01', '1960-08-01', '1960-09-01', '1960-10-01',\n               '1960-11-01', '1960-12-01'],\n              dtype='datetime64[ns]', name='date', length=144, freq=None)\n\n\n\ndf[\"1960-08-01\":\"1960-12-01\"]\n\n\n\n\n\n\n\n\nPassengers\n\n\ndate\n\n\n\n\n\n1960-08-01\n606\n\n\n1960-09-01\n508\n\n\n1960-10-01\n461\n\n\n1960-11-01\n390\n\n\n1960-12-01\n432\n\n\n\n\n\n\n\n\ndf.Passengers.resample('Y').mean()\n\ndate\n1949-12-31    126.666667\n1950-12-31    139.666667\n1951-12-31    170.166667\n1952-12-31    197.000000\n1953-12-31    225.000000\n1954-12-31    238.916667\n1955-12-31    284.000000\n1956-12-31    328.250000\n1957-12-31    368.416667\n1958-12-31    381.000000\n1959-12-31    428.333333\n1960-12-31    476.166667\nFreq: A-DEC, Name: Passengers, dtype: float64\n\n\n\ndf.Passengers.resample('Y').mean().plot()\n\n&lt;Axes: xlabel='date'&gt;\n\n\n\n\n\n\ndf = pd.read_csv(\"Data/aapl_no_dates.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n0\n153.17\n153.33\n152.22\n153.18\n16404088\n\n\n1\n153.58\n155.45\n152.89\n155.45\n27770715\n\n\n2\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n3\n153.90\n155.81\n153.78\n154.45\n26624926\n\n\n4\n155.02\n155.98\n154.48\n155.37\n21069647"
  },
  {
    "objectID": "pandas.html#business-days",
    "href": "pandas.html#business-days",
    "title": "Pandas",
    "section": "Business Days",
    "text": "Business Days\n\nrng = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq='B')\nrng\n\nDatetimeIndex(['2016-06-01', '2016-06-02', '2016-06-03', '2016-06-06',\n               '2016-06-07', '2016-06-08', '2016-06-09', '2016-06-10',\n               '2016-06-13', '2016-06-14', '2016-06-15', '2016-06-16',\n               '2016-06-17', '2016-06-20', '2016-06-21', '2016-06-22',\n               '2016-06-23', '2016-06-24', '2016-06-27', '2016-06-28',\n               '2016-06-29', '2016-06-30'],\n              dtype='datetime64[ns]', freq='B')\n\n\n\ndf.set_index(rng, inplace=True)\ndf.head()\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n2016-06-01\n153.17\n153.33\n152.22\n153.18\n16404088\n\n\n2016-06-02\n153.58\n155.45\n152.89\n155.45\n27770715\n\n\n2016-06-03\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-06\n153.90\n155.81\n153.78\n154.45\n26624926\n\n\n2016-06-07\n155.02\n155.98\n154.48\n155.37\n21069647\n\n\n\n\n\n\n\n\ndaily_index = pd.date_range(start=\"6/1/2016\",end=\"6/30/2016\",freq='D')\ndaily_index\n\nDatetimeIndex(['2016-06-01', '2016-06-02', '2016-06-03', '2016-06-04',\n               '2016-06-05', '2016-06-06', '2016-06-07', '2016-06-08',\n               '2016-06-09', '2016-06-10', '2016-06-11', '2016-06-12',\n               '2016-06-13', '2016-06-14', '2016-06-15', '2016-06-16',\n               '2016-06-17', '2016-06-18', '2016-06-19', '2016-06-20',\n               '2016-06-21', '2016-06-22', '2016-06-23', '2016-06-24',\n               '2016-06-25', '2016-06-26', '2016-06-27', '2016-06-28',\n               '2016-06-29', '2016-06-30'],\n              dtype='datetime64[ns]', freq='D')\n\n\n\ndaily_index.difference(df.index)\n\nDatetimeIndex(['2016-06-04', '2016-06-05', '2016-06-11', '2016-06-12',\n               '2016-06-18', '2016-06-19', '2016-06-25', '2016-06-26'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\nBenefits of having DatetimeIndex\n\ndf.Close.plot()\n\n&lt;Axes: &gt;\n\n\n\n\n\n\ndf[\"2016-06-01\":\"2016-06-10\"].Close.mean()\n\n152.72125\n\n\n\ndf.index\n\nDatetimeIndex(['2016-06-01', '2016-06-02', '2016-06-03', '2016-06-06',\n               '2016-06-07', '2016-06-08', '2016-06-09', '2016-06-10',\n               '2016-06-13', '2016-06-14', '2016-06-15', '2016-06-16',\n               '2016-06-17', '2016-06-20', '2016-06-21', '2016-06-22',\n               '2016-06-23', '2016-06-24', '2016-06-27', '2016-06-28',\n               '2016-06-29', '2016-06-30'],\n              dtype='datetime64[ns]', freq='B')\n\n\n\ndf.asfreq('D',method='pad').head()\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n2016-06-01\n153.17\n153.33\n152.22\n153.18\n16404088\n\n\n2016-06-02\n153.58\n155.45\n152.89\n155.45\n27770715\n\n\n2016-06-03\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-04\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-05\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n\n\n\n\n\n\ndf.asfreq('W',method='pad')\n\n\n\n\n\n\n\n\nOpen\nHigh\nLow\nClose\nVolume\n\n\n\n\n2016-06-05\n154.34\n154.45\n153.46\n153.93\n25331662\n\n\n2016-06-12\n145.74\n146.09\n142.51\n145.42\n72307330\n\n\n2016-06-19\n143.66\n146.74\n143.66\n146.34\n32541404\n\n\n2016-06-26\n147.17\n148.28\n145.38\n145.82\n25692361\n\n\n\n\n\n\n\n\n\nGenerating DatetimeIndex with periods argument\n\nrng = pd.date_range('1/1/2011', periods=72, freq='H')\nrng\n\nDatetimeIndex(['2011-01-01 00:00:00', '2011-01-01 01:00:00',\n               '2011-01-01 02:00:00', '2011-01-01 03:00:00',\n               '2011-01-01 04:00:00', '2011-01-01 05:00:00',\n               '2011-01-01 06:00:00', '2011-01-01 07:00:00',\n               '2011-01-01 08:00:00', '2011-01-01 09:00:00',\n               '2011-01-01 10:00:00', '2011-01-01 11:00:00',\n               '2011-01-01 12:00:00', '2011-01-01 13:00:00',\n               '2011-01-01 14:00:00', '2011-01-01 15:00:00',\n               '2011-01-01 16:00:00', '2011-01-01 17:00:00',\n               '2011-01-01 18:00:00', '2011-01-01 19:00:00',\n               '2011-01-01 20:00:00', '2011-01-01 21:00:00',\n               '2011-01-01 22:00:00', '2011-01-01 23:00:00',\n               '2011-01-02 00:00:00', '2011-01-02 01:00:00',\n               '2011-01-02 02:00:00', '2011-01-02 03:00:00',\n               '2011-01-02 04:00:00', '2011-01-02 05:00:00',\n               '2011-01-02 06:00:00', '2011-01-02 07:00:00',\n               '2011-01-02 08:00:00', '2011-01-02 09:00:00',\n               '2011-01-02 10:00:00', '2011-01-02 11:00:00',\n               '2011-01-02 12:00:00', '2011-01-02 13:00:00',\n               '2011-01-02 14:00:00', '2011-01-02 15:00:00',\n               '2011-01-02 16:00:00', '2011-01-02 17:00:00',\n               '2011-01-02 18:00:00', '2011-01-02 19:00:00',\n               '2011-01-02 20:00:00', '2011-01-02 21:00:00',\n               '2011-01-02 22:00:00', '2011-01-02 23:00:00',\n               '2011-01-03 00:00:00', '2011-01-03 01:00:00',\n               '2011-01-03 02:00:00', '2011-01-03 03:00:00',\n               '2011-01-03 04:00:00', '2011-01-03 05:00:00',\n               '2011-01-03 06:00:00', '2011-01-03 07:00:00',\n               '2011-01-03 08:00:00', '2011-01-03 09:00:00',\n               '2011-01-03 10:00:00', '2011-01-03 11:00:00',\n               '2011-01-03 12:00:00', '2011-01-03 13:00:00',\n               '2011-01-03 14:00:00', '2011-01-03 15:00:00',\n               '2011-01-03 16:00:00', '2011-01-03 17:00:00',\n               '2011-01-03 18:00:00', '2011-01-03 19:00:00',\n               '2011-01-03 20:00:00', '2011-01-03 21:00:00',\n               '2011-01-03 22:00:00', '2011-01-03 23:00:00'],\n              dtype='datetime64[ns]', freq='H')\n\n\n\nimport numpy as np\nts = pd.Series(np.random.randint(0,10,len(rng)), index=rng)\nts.head(20)\n\n2011-01-01 00:00:00    4\n2011-01-01 01:00:00    4\n2011-01-01 02:00:00    1\n2011-01-01 03:00:00    8\n2011-01-01 04:00:00    0\n2011-01-01 05:00:00    5\n2011-01-01 06:00:00    7\n2011-01-01 07:00:00    6\n2011-01-01 08:00:00    9\n2011-01-01 09:00:00    4\n2011-01-01 10:00:00    3\n2011-01-01 11:00:00    6\n2011-01-01 12:00:00    5\n2011-01-01 13:00:00    8\n2011-01-01 14:00:00    1\n2011-01-01 15:00:00    8\n2011-01-01 16:00:00    8\n2011-01-01 17:00:00    2\n2011-01-01 18:00:00    0\n2011-01-01 19:00:00    0\nFreq: H, dtype: int64\n\n\n\n\nHolidays\n\nrng = pd.date_range(start=\"7/1/2017\", end=\"7/21/2017\", freq='B')\nrng\n\nDatetimeIndex(['2017-07-03', '2017-07-04', '2017-07-05', '2017-07-06',\n               '2017-07-07', '2017-07-10', '2017-07-11', '2017-07-12',\n               '2017-07-13', '2017-07-14', '2017-07-17', '2017-07-18',\n               '2017-07-19', '2017-07-20', '2017-07-21'],\n              dtype='datetime64[ns]', freq='B')\n\n\n\n\nUsing CustomBusinessDay to generate US holidays calendar frequency\n\nfrom pandas.tseries.holiday import USFederalHolidayCalendar\nfrom pandas.tseries.offsets import CustomBusinessDay\n\nus_cal = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n\nrng = pd.date_range(start=\"7/1/2017\",end=\"7/23/2017\", freq=us_cal)\nrng\n\nDatetimeIndex(['2017-07-03', '2017-07-05', '2017-07-06', '2017-07-07',\n               '2017-07-10', '2017-07-11', '2017-07-12', '2017-07-13',\n               '2017-07-14', '2017-07-17', '2017-07-18', '2017-07-19',\n               '2017-07-20', '2017-07-21'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\n\nAbstractHolidayCalendar\n\nfrom pandas.tseries.holiday import AbstractHolidayCalendar, nearest_workday, Holiday\nclass myCalendar(AbstractHolidayCalendar):\n    rules = [\n        Holiday('My Birth Day', month=4, day=15, observance=nearest_workday),\n    ]\n    \nmy_bday = CustomBusinessDay(calendar=myCalendar())\npd.date_range('4/1/2017','4/30/2017',freq=my_bday)\n\nDatetimeIndex(['2017-04-03', '2017-04-04', '2017-04-05', '2017-04-06',\n               '2017-04-07', '2017-04-10', '2017-04-11', '2017-04-12',\n               '2017-04-13', '2017-04-17', '2017-04-18', '2017-04-19',\n               '2017-04-20', '2017-04-21', '2017-04-24', '2017-04-25',\n               '2017-04-26', '2017-04-27', '2017-04-28'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\n\nCustomBusinessDay\n\negypt_weekdays = \"Sun Mon Tue Wed Thu\"\n\nb = CustomBusinessDay(weekmask=egypt_weekdays)\n\npd.date_range(start=\"7/1/2017\",periods=20,freq=b)\n\nDatetimeIndex(['2017-07-02', '2017-07-03', '2017-07-04', '2017-07-05',\n               '2017-07-06', '2017-07-09', '2017-07-10', '2017-07-11',\n               '2017-07-12', '2017-07-13', '2017-07-16', '2017-07-17',\n               '2017-07-18', '2017-07-19', '2017-07-20', '2017-07-23',\n               '2017-07-24', '2017-07-25', '2017-07-26', '2017-07-27'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\nb = CustomBusinessDay(holidays=['2017-07-04', '2017-07-10'], weekmask=egypt_weekdays)\n\npd.date_range(start=\"7/1/2017\",periods=20,freq=b)\n\nDatetimeIndex(['2017-07-02', '2017-07-03', '2017-07-05', '2017-07-06',\n               '2017-07-09', '2017-07-11', '2017-07-12', '2017-07-13',\n               '2017-07-16', '2017-07-17', '2017-07-18', '2017-07-19',\n               '2017-07-20', '2017-07-23', '2017-07-24', '2017-07-25',\n               '2017-07-26', '2017-07-27', '2017-07-30', '2017-07-31'],\n              dtype='datetime64[ns]', freq='C')\n\n\n\n\nMaths\n\nfrom datetime import datetime\ndt = datetime(2017,7,9)\ndt\n\ndatetime.datetime(2017, 7, 9, 0, 0)\n\n\n\ndt + 1*b\n\nTimestamp('2017-07-11 00:00:00')"
  },
  {
    "objectID": "pandas.html#to-datatime",
    "href": "pandas.html#to-datatime",
    "title": "Pandas",
    "section": "To datatime",
    "text": "To datatime\n\nimport pandas as pd\ndates = ['2017-01-05', 'Jan 5, 2017', '01/05/2017', '2017.01.05', '2017/01/05','20170105']\npd.to_datetime(dates)\n\nDatetimeIndex(['2017-01-05', '2017-01-05', '2017-01-05', '2017-01-05',\n               '2017-01-05', '2017-01-05'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\ndt = ['2017-01-05 2:30:00 PM', 'Jan 5, 2017 14:30:00', '01/05/2016', '2017.01.05', '2017/01/05','20170105']\npd.to_datetime(dt)\n\nDatetimeIndex(['2017-01-05 14:30:00', '2017-01-05 14:30:00',\n               '2016-01-05 00:00:00', '2017-01-05 00:00:00',\n               '2017-01-05 00:00:00', '2017-01-05 00:00:00'],\n              dtype='datetime64[ns]', freq=None)\n\n\n\nEuropean style dates with day first\n\npd.to_datetime('30-12-2016', dayfirst=True)\n\nTimestamp('2016-12-30 00:00:00')\n\n\n\npd.to_datetime('5-1-2016', dayfirst=True)\n\nTimestamp('2016-01-05 00:00:00')\n\n\n\n\nCustom date time format\n\npd.to_datetime('2017$01$05', format='%Y$%m$%d')\n\nTimestamp('2017-01-05 00:00:00')\n\n\n\npd.to_datetime('2017#01#05', format='%Y#%m#%d')\n\nTimestamp('2017-01-05 00:00:00')\n\n\n\n\nHandling invalid dates\n\npd.to_datetime(['2017-01-05', 'Jan 6, 2017', 'abc'], errors='ignore')\n\nIndex(['2017-01-05', 'Jan 6, 2017', 'abc'], dtype='object')\n\n\n\npd.to_datetime(['2017-01-05', 'Jan 6, 2017', 'abc'], errors='coerce')\n\nDatetimeIndex(['2017-01-05', '2017-01-06', 'NaT'], dtype='datetime64[ns]', freq=None)"
  },
  {
    "objectID": "pandas.html#epoch",
    "href": "pandas.html#epoch",
    "title": "Pandas",
    "section": "Epoch",
    "text": "Epoch\n\ncurrent_epoch = 1501324478\npd.to_datetime(current_epoch, unit='s')\n\nTimestamp('2017-07-29 10:34:38')\n\n\n\npd.to_datetime(current_epoch*1000, unit='ms')\n\nTimestamp('2017-07-29 10:34:38')\n\n\n\nt = pd.to_datetime([current_epoch], unit='s')\nt\n\nDatetimeIndex(['2017-07-29 10:34:38'], dtype='datetime64[ns]', freq=None)\n\n\n\nt.view('int64')\n\narray([1501324478000000000])\n\n\n\nYearly Period\n\nimport pandas as pd\ny = pd.Period('2016')\ny\n\nPeriod('2016', 'A-DEC')\n\n\n\ny.start_time\n\nTimestamp('2016-01-01 00:00:00')\n\n\n\ny.end_time\n\nTimestamp('2016-12-31 23:59:59.999999999')\n\n\n\ny.is_leap_year\n\nTrue\n\n\n\n\nMonthly Period\n\nm = pd.Period('2017-12')\nm\n\nPeriod('2017-12', 'M')\n\n\n\nm.start_time\n\nTimestamp('2017-12-01 00:00:00')\n\n\n\nm.end_time\n\nTimestamp('2017-12-31 23:59:59.999999999')\n\n\n\nm+1\n\nPeriod('2018-01', 'M')\n\n\n\n\nDaily Period\n\nd = pd.Period('2016-02-28', freq='D')\nd\n\nPeriod('2016-02-28', 'D')\n\n\n\nd.start_time\n\nTimestamp('2016-02-28 00:00:00')\n\n\n\nd.end_time\n\nTimestamp('2016-02-28 23:59:59.999999999')\n\n\n\nd+1\n\nPeriod('2016-02-29', 'D')\n\n\n\n\nHourly Period\n\nh = pd.Period('2017-08-15 23:00:00',freq='H')\nh\n\nPeriod('2017-08-15 23:00', 'H')\n\n\n\nh+1\n\nPeriod('2017-08-16 00:00', 'H')\n\n\n\nh+pd.offsets.Hour(1)\n\nPeriod('2017-08-16 00:00', 'H')\n\n\n\n\nQuarterly Period\n\nq1= pd.Period('2017Q1', freq='Q-JAN')\nq1\n\nPeriod('2017Q1', 'Q-JAN')\n\n\n\nq1.start_time\n\nTimestamp('2016-02-01 00:00:00')\n\n\n\nq1.end_time\n\nTimestamp('2016-04-30 23:59:59.999999999')\n\n\n\nq1.asfreq('M',how='start')\n\nPeriod('2016-02', 'M')\n\n\n\nq1.asfreq('M',how='end')\n\nPeriod('2016-04', 'M')\n\n\n\n\nWeekly Period\n\nw = pd.Period('2017-07-05',freq='W')\nw\n\nPeriod('2017-07-03/2017-07-09', 'W-SUN')\n\n\n\nw-1\n\nPeriod('2017-06-26/2017-07-02', 'W-SUN')\n\n\n\nw2 = pd.Period('2017-08-15',freq='W')\nw2\n\nPeriod('2017-08-14/2017-08-20', 'W-SUN')\n\n\n\nw2-w\n\n&lt;6 * Weeks: weekday=6&gt;\n\n\n\n\nPeriodIndex and period_range\n\nr = pd.period_range('2011', '2017', freq='q')\nr\n\nPeriodIndex(['2011Q1', '2011Q2', '2011Q3', '2011Q4', '2012Q1', '2012Q2',\n             '2012Q3', '2012Q4', '2013Q1', '2013Q2', '2013Q3', '2013Q4',\n             '2014Q1', '2014Q2', '2014Q3', '2014Q4', '2015Q1', '2015Q2',\n             '2015Q3', '2015Q4', '2016Q1', '2016Q2', '2016Q3', '2016Q4',\n             '2017Q1'],\n            dtype='period[Q-DEC]')\n\n\n\nr[0].start_time\n\nTimestamp('2011-01-01 00:00:00')\n\n\n\nr[0].end_time\n\nTimestamp('2011-03-31 23:59:59.999999999')\n\n\n\nidx = pd.period_range('2011', '2017', freq='q-jan')\nidx\n\nPeriodIndex(['2011Q4', '2012Q1', '2012Q2', '2012Q3', '2012Q4', '2013Q1',\n             '2013Q2', '2013Q3', '2013Q4', '2014Q1', '2014Q2', '2014Q3',\n             '2014Q4', '2015Q1', '2015Q2', '2015Q3', '2015Q4', '2016Q1',\n             '2016Q2', '2016Q3', '2016Q4', '2017Q1', '2017Q2', '2017Q3',\n             '2017Q4'],\n            dtype='period[Q-JAN]')\n\n\n\nr[0].start_time\n\nTimestamp('2011-01-01 00:00:00')\n\n\n\nr[0].end_time\n\nTimestamp('2011-03-31 23:59:59.999999999')\n\n\n\nr = pd.period_range(start='2016-01', periods=10, freq='M')\nr\n\nPeriodIndex(['2016-01', '2016-02', '2016-03', '2016-04', '2016-05', '2016-06',\n             '2016-07', '2016-08', '2016-09', '2016-10'],\n            dtype='period[M]')\n\n\n\nimport numpy as np\nps = pd.Series(np.random.randn(len(idx)), idx)\nps\n\n2011Q4   -0.412550\n2012Q1    0.701174\n2012Q2    0.385101\n2012Q3    0.989325\n2012Q4   -0.858848\n2013Q1   -0.137989\n2013Q2    0.410097\n2013Q3    1.391899\n2013Q4    1.414134\n2014Q1   -0.144215\n2014Q2   -0.305327\n2014Q3    0.025925\n2014Q4    0.269103\n2015Q1    1.953641\n2015Q2    1.455620\n2015Q3    0.403967\n2015Q4    1.119294\n2016Q1    0.650177\n2016Q2    1.216127\n2016Q3   -0.784484\n2016Q4   -2.146994\n2017Q1    0.410092\n2017Q2    1.031284\n2017Q3    0.681366\n2017Q4   -1.082856\nFreq: Q-JAN, dtype: float64\n\n\n\nps['2016']\n\n2016Q4   -2.146994\n2017Q1    0.410092\n2017Q2    1.031284\n2017Q3    0.681366\n2017Q4   -1.082856\nFreq: Q-JAN, dtype: float64\n\n\n\nps['2016':'2017']\n\n2016Q4   -2.146994\n2017Q1    0.410092\n2017Q2    1.031284\n2017Q3    0.681366\n2017Q4   -1.082856\nFreq: Q-JAN, dtype: float64\n\n\n\npst = ps.to_timestamp()\npst\n\n2010-11-01   -0.412550\n2011-02-01    0.701174\n2011-05-01    0.385101\n2011-08-01    0.989325\n2011-11-01   -0.858848\n2012-02-01   -0.137989\n2012-05-01    0.410097\n2012-08-01    1.391899\n2012-11-01    1.414134\n2013-02-01   -0.144215\n2013-05-01   -0.305327\n2013-08-01    0.025925\n2013-11-01    0.269103\n2014-02-01    1.953641\n2014-05-01    1.455620\n2014-08-01    0.403967\n2014-11-01    1.119294\n2015-02-01    0.650177\n2015-05-01    1.216127\n2015-08-01   -0.784484\n2015-11-01   -2.146994\n2016-02-01    0.410092\n2016-05-01    1.031284\n2016-08-01    0.681366\n2016-11-01   -1.082856\nFreq: QS-NOV, dtype: float64\n\n\n\npst.index\n\nDatetimeIndex(['2010-11-01', '2011-02-01', '2011-05-01', '2011-08-01',\n               '2011-11-01', '2012-02-01', '2012-05-01', '2012-08-01',\n               '2012-11-01', '2013-02-01', '2013-05-01', '2013-08-01',\n               '2013-11-01', '2014-02-01', '2014-05-01', '2014-08-01',\n               '2014-11-01', '2015-02-01', '2015-05-01', '2015-08-01',\n               '2015-11-01', '2016-02-01', '2016-05-01', '2016-08-01',\n               '2016-11-01'],\n              dtype='datetime64[ns]', freq='QS-NOV')\n\n\n\nps = pst.to_period()\nps\n\n2010Q4   -0.412550\n2011Q1    0.701174\n2011Q2    0.385101\n2011Q3    0.989325\n2011Q4   -0.858848\n2012Q1   -0.137989\n2012Q2    0.410097\n2012Q3    1.391899\n2012Q4    1.414134\n2013Q1   -0.144215\n2013Q2   -0.305327\n2013Q3    0.025925\n2013Q4    0.269103\n2014Q1    1.953641\n2014Q2    1.455620\n2014Q3    0.403967\n2014Q4    1.119294\n2015Q1    0.650177\n2015Q2    1.216127\n2015Q3   -0.784484\n2015Q4   -2.146994\n2016Q1    0.410092\n2016Q2    1.031284\n2016Q3    0.681366\n2016Q4   -1.082856\nFreq: Q-DEC, dtype: float64\n\n\n\nps.index\n\nPeriodIndex(['2010Q4', '2011Q1', '2011Q2', '2011Q3', '2011Q4', '2012Q1',\n             '2012Q2', '2012Q3', '2012Q4', '2013Q1', '2013Q2', '2013Q3',\n             '2013Q4', '2014Q1', '2014Q2', '2014Q3', '2014Q4', '2015Q1',\n             '2015Q2', '2015Q3', '2015Q4', '2016Q1', '2016Q2', '2016Q3',\n             '2016Q4'],\n            dtype='period[Q-DEC]')"
  },
  {
    "objectID": "pandas.html#processing-wal-marts-financials",
    "href": "pandas.html#processing-wal-marts-financials",
    "title": "Pandas",
    "section": "Processing Wal Mart’s Financials",
    "text": "Processing Wal Mart’s Financials\n\nimport pandas as pd\ndf = pd.read_csv(\"Data/wmt.csv\")\ndf\n\n\n\n\n\n\n\n\nLine Item\n2017Q1\n2017Q2\n2017Q3\n2017Q4\n2018Q1\n\n\n\n\n0\nRevenue\n115904\n120854\n118179\n130936\n117542\n\n\n1\nExpenses\n86544\n89485\n87484\n97743\n87688\n\n\n2\nProfit\n29360\n31369\n30695\n33193\n29854\n\n\n\n\n\n\n\n\ndf.set_index(\"Line Item\",inplace=True)\ndf = df.T\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\n\n\n\n\n2017Q1\n115904\n86544\n29360\n\n\n2017Q2\n120854\n89485\n31369\n\n\n2017Q3\n118179\n87484\n30695\n\n\n2017Q4\n130936\n97743\n33193\n\n\n2018Q1\n117542\n87688\n29854\n\n\n\n\n\n\n\n\ndf.index\n\nIndex(['2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1'], dtype='object')\n\n\n\ndf.index = pd.PeriodIndex(df.index, freq=\"Q-JAN\")\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\n\n\n\n\n2017Q1\n115904\n86544\n29360\n\n\n2017Q2\n120854\n89485\n31369\n\n\n2017Q3\n118179\n87484\n30695\n\n\n2017Q4\n130936\n97743\n33193\n\n\n2018Q1\n117542\n87688\n29854\n\n\n\n\n\n\n\n\ndf.index\n\nPeriodIndex(['2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1'], dtype='period[Q-JAN]')\n\n\n\ndf.index[0].start_time\n\nTimestamp('2016-02-01 00:00:00')\n\n\n\nAdd start date end date columns to dataframe\n\ndf[\"Start Date\"]=df.index.map(lambda x: x.start_time)\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\nStart Date\n\n\n\n\n2017Q1\n115904\n86544\n29360\n2016-02-01\n\n\n2017Q2\n120854\n89485\n31369\n2016-05-01\n\n\n2017Q3\n118179\n87484\n30695\n2016-08-01\n\n\n2017Q4\n130936\n97743\n33193\n2016-11-01\n\n\n2018Q1\n117542\n87688\n29854\n2017-02-01\n\n\n\n\n\n\n\n\ndf[\"End Date\"]=df.index.map(lambda x: x.end_time)\ndf\n\n\n\n\n\n\n\nLine Item\nRevenue\nExpenses\nProfit\nStart Date\nEnd Date\n\n\n\n\n2017Q1\n115904\n86544\n29360\n2016-02-01\n2016-04-30 23:59:59.999999999\n\n\n2017Q2\n120854\n89485\n31369\n2016-05-01\n2016-07-31 23:59:59.999999999\n\n\n2017Q3\n118179\n87484\n30695\n2016-08-01\n2016-10-31 23:59:59.999999999\n\n\n2017Q4\n130936\n97743\n33193\n2016-11-01\n2017-01-31 23:59:59.999999999\n\n\n2018Q1\n117542\n87688\n29854\n2017-02-01\n2017-04-30 23:59:59.999999999"
  },
  {
    "objectID": "pandas.html#timezone-handling",
    "href": "pandas.html#timezone-handling",
    "title": "Pandas",
    "section": "Timezone Handling",
    "text": "Timezone Handling\n\nimport pandas as pd\ndf = pd.read_csv(\"Data/msft.csv\", header=1,index_col='Date Time',parse_dates=True)\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 09:00:00\n72.38\n\n\n2017-08-17 09:15:00\n71.00\n\n\n2017-08-17 09:30:00\n71.67\n\n\n2017-08-17 10:00:00\n72.80\n\n\n2017-08-17 10:30:00\n73.00\n\n\n2017-08-17 11:00:00\n72.50\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2017-08-17 09:00:00', '2017-08-17 09:15:00',\n               '2017-08-17 09:30:00', '2017-08-17 10:00:00',\n               '2017-08-17 10:30:00', '2017-08-17 11:00:00'],\n              dtype='datetime64[ns]', name='Date Time', freq=None)\n\n\n\ndf.tz_localize(tz='US/Eastern')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 09:00:00\n72.38\n\n\n2017-08-17 09:15:00\n71.00\n\n\n2017-08-17 09:30:00\n71.67\n\n\n2017-08-17 10:00:00\n72.80\n\n\n2017-08-17 10:30:00\n73.00\n\n\n2017-08-17 11:00:00\n72.50\n\n\n\n\n\n\n\n\ndf.index = df.index.tz_localize(tz='US/Eastern')\ndf.index\n\nDatetimeIndex(['2017-08-17 09:00:00-04:00', '2017-08-17 09:15:00-04:00',\n               '2017-08-17 09:30:00-04:00', '2017-08-17 10:00:00-04:00',\n               '2017-08-17 10:30:00-04:00', '2017-08-17 11:00:00-04:00'],\n              dtype='datetime64[ns, US/Eastern]', name='Date Time', freq=None)\n\n\n\nConvert to Berlin time using tz_convert\n\ndf = df.tz_convert('Europe/Berlin')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 15:00:00+02:00\n72.38\n\n\n2017-08-17 15:15:00+02:00\n71.00\n\n\n2017-08-17 15:30:00+02:00\n71.67\n\n\n2017-08-17 16:00:00+02:00\n72.80\n\n\n2017-08-17 16:30:00+02:00\n73.00\n\n\n2017-08-17 17:00:00+02:00\n72.50\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2017-08-17 15:00:00+02:00', '2017-08-17 15:15:00+02:00',\n               '2017-08-17 15:30:00+02:00', '2017-08-17 16:00:00+02:00',\n               '2017-08-17 16:30:00+02:00', '2017-08-17 17:00:00+02:00'],\n              dtype='datetime64[ns, Europe/Berlin]', name='Date Time', freq=None)\n\n\n\nfrom pytz import all_timezones\nprint (all_timezones)\n\n['Africa/Abidjan', 'Africa/Accra', 'Africa/Addis_Ababa', 'Africa/Algiers', 'Africa/Asmara', 'Africa/Asmera', 'Africa/Bamako', 'Africa/Bangui', 'Africa/Banjul', 'Africa/Bissau', 'Africa/Blantyre', 'Africa/Brazzaville', 'Africa/Bujumbura', 'Africa/Cairo', 'Africa/Casablanca', 'Africa/Ceuta', 'Africa/Conakry', 'Africa/Dakar', 'Africa/Dar_es_Salaam', 'Africa/Djibouti', 'Africa/Douala', 'Africa/El_Aaiun', 'Africa/Freetown', 'Africa/Gaborone', 'Africa/Harare', 'Africa/Johannesburg', 'Africa/Juba', 'Africa/Kampala', 'Africa/Khartoum', 'Africa/Kigali', 'Africa/Kinshasa', 'Africa/Lagos', 'Africa/Libreville', 'Africa/Lome', 'Africa/Luanda', 'Africa/Lubumbashi', 'Africa/Lusaka', 'Africa/Malabo', 'Africa/Maputo', 'Africa/Maseru', 'Africa/Mbabane', 'Africa/Mogadishu', 'Africa/Monrovia', 'Africa/Nairobi', 'Africa/Ndjamena', 'Africa/Niamey', 'Africa/Nouakchott', 'Africa/Ouagadougou', 'Africa/Porto-Novo', 'Africa/Sao_Tome', 'Africa/Timbuktu', 'Africa/Tripoli', 'Africa/Tunis', 'Africa/Windhoek', 'America/Adak', 'America/Anchorage', 'America/Anguilla', 'America/Antigua', 'America/Araguaina', 'America/Argentina/Buenos_Aires', 'America/Argentina/Catamarca', 'America/Argentina/ComodRivadavia', 'America/Argentina/Cordoba', 'America/Argentina/Jujuy', 'America/Argentina/La_Rioja', 'America/Argentina/Mendoza', 'America/Argentina/Rio_Gallegos', 'America/Argentina/Salta', 'America/Argentina/San_Juan', 'America/Argentina/San_Luis', 'America/Argentina/Tucuman', 'America/Argentina/Ushuaia', 'America/Aruba', 'America/Asuncion', 'America/Atikokan', 'America/Atka', 'America/Bahia', 'America/Bahia_Banderas', 'America/Barbados', 'America/Belem', 'America/Belize', 'America/Blanc-Sablon', 'America/Boa_Vista', 'America/Bogota', 'America/Boise', 'America/Buenos_Aires', 'America/Cambridge_Bay', 'America/Campo_Grande', 'America/Cancun', 'America/Caracas', 'America/Catamarca', 'America/Cayenne', 'America/Cayman', 'America/Chicago', 'America/Chihuahua', 'America/Ciudad_Juarez', 'America/Coral_Harbour', 'America/Cordoba', 'America/Costa_Rica', 'America/Creston', 'America/Cuiaba', 'America/Curacao', 'America/Danmarkshavn', 'America/Dawson', 'America/Dawson_Creek', 'America/Denver', 'America/Detroit', 'America/Dominica', 'America/Edmonton', 'America/Eirunepe', 'America/El_Salvador', 'America/Ensenada', 'America/Fort_Nelson', 'America/Fort_Wayne', 'America/Fortaleza', 'America/Glace_Bay', 'America/Godthab', 'America/Goose_Bay', 'America/Grand_Turk', 'America/Grenada', 'America/Guadeloupe', 'America/Guatemala', 'America/Guayaquil', 'America/Guyana', 'America/Halifax', 'America/Havana', 'America/Hermosillo', 'America/Indiana/Indianapolis', 'America/Indiana/Knox', 'America/Indiana/Marengo', 'America/Indiana/Petersburg', 'America/Indiana/Tell_City', 'America/Indiana/Vevay', 'America/Indiana/Vincennes', 'America/Indiana/Winamac', 'America/Indianapolis', 'America/Inuvik', 'America/Iqaluit', 'America/Jamaica', 'America/Jujuy', 'America/Juneau', 'America/Kentucky/Louisville', 'America/Kentucky/Monticello', 'America/Knox_IN', 'America/Kralendijk', 'America/La_Paz', 'America/Lima', 'America/Los_Angeles', 'America/Louisville', 'America/Lower_Princes', 'America/Maceio', 'America/Managua', 'America/Manaus', 'America/Marigot', 'America/Martinique', 'America/Matamoros', 'America/Mazatlan', 'America/Mendoza', 'America/Menominee', 'America/Merida', 'America/Metlakatla', 'America/Mexico_City', 'America/Miquelon', 'America/Moncton', 'America/Monterrey', 'America/Montevideo', 'America/Montreal', 'America/Montserrat', 'America/Nassau', 'America/New_York', 'America/Nipigon', 'America/Nome', 'America/Noronha', 'America/North_Dakota/Beulah', 'America/North_Dakota/Center', 'America/North_Dakota/New_Salem', 'America/Nuuk', 'America/Ojinaga', 'America/Panama', 'America/Pangnirtung', 'America/Paramaribo', 'America/Phoenix', 'America/Port-au-Prince', 'America/Port_of_Spain', 'America/Porto_Acre', 'America/Porto_Velho', 'America/Puerto_Rico', 'America/Punta_Arenas', 'America/Rainy_River', 'America/Rankin_Inlet', 'America/Recife', 'America/Regina', 'America/Resolute', 'America/Rio_Branco', 'America/Rosario', 'America/Santa_Isabel', 'America/Santarem', 'America/Santiago', 'America/Santo_Domingo', 'America/Sao_Paulo', 'America/Scoresbysund', 'America/Shiprock', 'America/Sitka', 'America/St_Barthelemy', 'America/St_Johns', 'America/St_Kitts', 'America/St_Lucia', 'America/St_Thomas', 'America/St_Vincent', 'America/Swift_Current', 'America/Tegucigalpa', 'America/Thule', 'America/Thunder_Bay', 'America/Tijuana', 'America/Toronto', 'America/Tortola', 'America/Vancouver', 'America/Virgin', 'America/Whitehorse', 'America/Winnipeg', 'America/Yakutat', 'America/Yellowknife', 'Antarctica/Casey', 'Antarctica/Davis', 'Antarctica/DumontDUrville', 'Antarctica/Macquarie', 'Antarctica/Mawson', 'Antarctica/McMurdo', 'Antarctica/Palmer', 'Antarctica/Rothera', 'Antarctica/South_Pole', 'Antarctica/Syowa', 'Antarctica/Troll', 'Antarctica/Vostok', 'Arctic/Longyearbyen', 'Asia/Aden', 'Asia/Almaty', 'Asia/Amman', 'Asia/Anadyr', 'Asia/Aqtau', 'Asia/Aqtobe', 'Asia/Ashgabat', 'Asia/Ashkhabad', 'Asia/Atyrau', 'Asia/Baghdad', 'Asia/Bahrain', 'Asia/Baku', 'Asia/Bangkok', 'Asia/Barnaul', 'Asia/Beirut', 'Asia/Bishkek', 'Asia/Brunei', 'Asia/Calcutta', 'Asia/Chita', 'Asia/Choibalsan', 'Asia/Chongqing', 'Asia/Chungking', 'Asia/Colombo', 'Asia/Dacca', 'Asia/Damascus', 'Asia/Dhaka', 'Asia/Dili', 'Asia/Dubai', 'Asia/Dushanbe', 'Asia/Famagusta', 'Asia/Gaza', 'Asia/Harbin', 'Asia/Hebron', 'Asia/Ho_Chi_Minh', 'Asia/Hong_Kong', 'Asia/Hovd', 'Asia/Irkutsk', 'Asia/Istanbul', 'Asia/Jakarta', 'Asia/Jayapura', 'Asia/Jerusalem', 'Asia/Kabul', 'Asia/Kamchatka', 'Asia/Karachi', 'Asia/Kashgar', 'Asia/Kathmandu', 'Asia/Katmandu', 'Asia/Khandyga', 'Asia/Kolkata', 'Asia/Krasnoyarsk', 'Asia/Kuala_Lumpur', 'Asia/Kuching', 'Asia/Kuwait', 'Asia/Macao', 'Asia/Macau', 'Asia/Magadan', 'Asia/Makassar', 'Asia/Manila', 'Asia/Muscat', 'Asia/Nicosia', 'Asia/Novokuznetsk', 'Asia/Novosibirsk', 'Asia/Omsk', 'Asia/Oral', 'Asia/Phnom_Penh', 'Asia/Pontianak', 'Asia/Pyongyang', 'Asia/Qatar', 'Asia/Qostanay', 'Asia/Qyzylorda', 'Asia/Rangoon', 'Asia/Riyadh', 'Asia/Saigon', 'Asia/Sakhalin', 'Asia/Samarkand', 'Asia/Seoul', 'Asia/Shanghai', 'Asia/Singapore', 'Asia/Srednekolymsk', 'Asia/Taipei', 'Asia/Tashkent', 'Asia/Tbilisi', 'Asia/Tehran', 'Asia/Tel_Aviv', 'Asia/Thimbu', 'Asia/Thimphu', 'Asia/Tokyo', 'Asia/Tomsk', 'Asia/Ujung_Pandang', 'Asia/Ulaanbaatar', 'Asia/Ulan_Bator', 'Asia/Urumqi', 'Asia/Ust-Nera', 'Asia/Vientiane', 'Asia/Vladivostok', 'Asia/Yakutsk', 'Asia/Yangon', 'Asia/Yekaterinburg', 'Asia/Yerevan', 'Atlantic/Azores', 'Atlantic/Bermuda', 'Atlantic/Canary', 'Atlantic/Cape_Verde', 'Atlantic/Faeroe', 'Atlantic/Faroe', 'Atlantic/Jan_Mayen', 'Atlantic/Madeira', 'Atlantic/Reykjavik', 'Atlantic/South_Georgia', 'Atlantic/St_Helena', 'Atlantic/Stanley', 'Australia/ACT', 'Australia/Adelaide', 'Australia/Brisbane', 'Australia/Broken_Hill', 'Australia/Canberra', 'Australia/Currie', 'Australia/Darwin', 'Australia/Eucla', 'Australia/Hobart', 'Australia/LHI', 'Australia/Lindeman', 'Australia/Lord_Howe', 'Australia/Melbourne', 'Australia/NSW', 'Australia/North', 'Australia/Perth', 'Australia/Queensland', 'Australia/South', 'Australia/Sydney', 'Australia/Tasmania', 'Australia/Victoria', 'Australia/West', 'Australia/Yancowinna', 'Brazil/Acre', 'Brazil/DeNoronha', 'Brazil/East', 'Brazil/West', 'CET', 'CST6CDT', 'Canada/Atlantic', 'Canada/Central', 'Canada/Eastern', 'Canada/Mountain', 'Canada/Newfoundland', 'Canada/Pacific', 'Canada/Saskatchewan', 'Canada/Yukon', 'Chile/Continental', 'Chile/EasterIsland', 'Cuba', 'EET', 'EST', 'EST5EDT', 'Egypt', 'Eire', 'Etc/GMT', 'Etc/GMT+0', 'Etc/GMT+1', 'Etc/GMT+10', 'Etc/GMT+11', 'Etc/GMT+12', 'Etc/GMT+2', 'Etc/GMT+3', 'Etc/GMT+4', 'Etc/GMT+5', 'Etc/GMT+6', 'Etc/GMT+7', 'Etc/GMT+8', 'Etc/GMT+9', 'Etc/GMT-0', 'Etc/GMT-1', 'Etc/GMT-10', 'Etc/GMT-11', 'Etc/GMT-12', 'Etc/GMT-13', 'Etc/GMT-14', 'Etc/GMT-2', 'Etc/GMT-3', 'Etc/GMT-4', 'Etc/GMT-5', 'Etc/GMT-6', 'Etc/GMT-7', 'Etc/GMT-8', 'Etc/GMT-9', 'Etc/GMT0', 'Etc/Greenwich', 'Etc/UCT', 'Etc/UTC', 'Etc/Universal', 'Etc/Zulu', 'Europe/Amsterdam', 'Europe/Andorra', 'Europe/Astrakhan', 'Europe/Athens', 'Europe/Belfast', 'Europe/Belgrade', 'Europe/Berlin', 'Europe/Bratislava', 'Europe/Brussels', 'Europe/Bucharest', 'Europe/Budapest', 'Europe/Busingen', 'Europe/Chisinau', 'Europe/Copenhagen', 'Europe/Dublin', 'Europe/Gibraltar', 'Europe/Guernsey', 'Europe/Helsinki', 'Europe/Isle_of_Man', 'Europe/Istanbul', 'Europe/Jersey', 'Europe/Kaliningrad', 'Europe/Kiev', 'Europe/Kirov', 'Europe/Kyiv', 'Europe/Lisbon', 'Europe/Ljubljana', 'Europe/London', 'Europe/Luxembourg', 'Europe/Madrid', 'Europe/Malta', 'Europe/Mariehamn', 'Europe/Minsk', 'Europe/Monaco', 'Europe/Moscow', 'Europe/Nicosia', 'Europe/Oslo', 'Europe/Paris', 'Europe/Podgorica', 'Europe/Prague', 'Europe/Riga', 'Europe/Rome', 'Europe/Samara', 'Europe/San_Marino', 'Europe/Sarajevo', 'Europe/Saratov', 'Europe/Simferopol', 'Europe/Skopje', 'Europe/Sofia', 'Europe/Stockholm', 'Europe/Tallinn', 'Europe/Tirane', 'Europe/Tiraspol', 'Europe/Ulyanovsk', 'Europe/Uzhgorod', 'Europe/Vaduz', 'Europe/Vatican', 'Europe/Vienna', 'Europe/Vilnius', 'Europe/Volgograd', 'Europe/Warsaw', 'Europe/Zagreb', 'Europe/Zaporozhye', 'Europe/Zurich', 'GB', 'GB-Eire', 'GMT', 'GMT+0', 'GMT-0', 'GMT0', 'Greenwich', 'HST', 'Hongkong', 'Iceland', 'Indian/Antananarivo', 'Indian/Chagos', 'Indian/Christmas', 'Indian/Cocos', 'Indian/Comoro', 'Indian/Kerguelen', 'Indian/Mahe', 'Indian/Maldives', 'Indian/Mauritius', 'Indian/Mayotte', 'Indian/Reunion', 'Iran', 'Israel', 'Jamaica', 'Japan', 'Kwajalein', 'Libya', 'MET', 'MST', 'MST7MDT', 'Mexico/BajaNorte', 'Mexico/BajaSur', 'Mexico/General', 'NZ', 'NZ-CHAT', 'Navajo', 'PRC', 'PST8PDT', 'Pacific/Apia', 'Pacific/Auckland', 'Pacific/Bougainville', 'Pacific/Chatham', 'Pacific/Chuuk', 'Pacific/Easter', 'Pacific/Efate', 'Pacific/Enderbury', 'Pacific/Fakaofo', 'Pacific/Fiji', 'Pacific/Funafuti', 'Pacific/Galapagos', 'Pacific/Gambier', 'Pacific/Guadalcanal', 'Pacific/Guam', 'Pacific/Honolulu', 'Pacific/Johnston', 'Pacific/Kanton', 'Pacific/Kiritimati', 'Pacific/Kosrae', 'Pacific/Kwajalein', 'Pacific/Majuro', 'Pacific/Marquesas', 'Pacific/Midway', 'Pacific/Nauru', 'Pacific/Niue', 'Pacific/Norfolk', 'Pacific/Noumea', 'Pacific/Pago_Pago', 'Pacific/Palau', 'Pacific/Pitcairn', 'Pacific/Pohnpei', 'Pacific/Ponape', 'Pacific/Port_Moresby', 'Pacific/Rarotonga', 'Pacific/Saipan', 'Pacific/Samoa', 'Pacific/Tahiti', 'Pacific/Tarawa', 'Pacific/Tongatapu', 'Pacific/Truk', 'Pacific/Wake', 'Pacific/Wallis', 'Pacific/Yap', 'Poland', 'Portugal', 'ROC', 'ROK', 'Singapore', 'Turkey', 'UCT', 'US/Alaska', 'US/Aleutian', 'US/Arizona', 'US/Central', 'US/East-Indiana', 'US/Eastern', 'US/Hawaii', 'US/Indiana-Starke', 'US/Michigan', 'US/Mountain', 'US/Pacific', 'US/Samoa', 'UTC', 'Universal', 'W-SU', 'WET', 'Zulu']\n\n\n\n\nConvert to Mumbai time\n\ndf.index = df.index.tz_convert('Asia/Calcutta') # tz database doesn't have any Mumbai timezone but calcutta and mumbai are both in same timezone so we will use that\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate Time\n\n\n\n\n\n2017-08-17 18:30:00+05:30\n72.38\n\n\n2017-08-17 18:45:00+05:30\n71.00\n\n\n2017-08-17 19:00:00+05:30\n71.67\n\n\n2017-08-17 19:30:00+05:30\n72.80\n\n\n2017-08-17 20:00:00+05:30\n73.00\n\n\n2017-08-17 20:30:00+05:30\n72.50\n\n\n\n\n\n\n\n\n\nUsing timezones in date_range\n\n(1) timezone using pytz\n\nlondon = pd.date_range('3/6/2012 00:09:00', periods=10, freq='H',tz='Europe/London')\nlondon\n\nDatetimeIndex(['2012-03-06 00:09:00+00:00', '2012-03-06 01:09:00+00:00',\n               '2012-03-06 02:09:00+00:00', '2012-03-06 03:09:00+00:00',\n               '2012-03-06 04:09:00+00:00', '2012-03-06 05:09:00+00:00',\n               '2012-03-06 06:09:00+00:00', '2012-03-06 07:09:00+00:00',\n               '2012-03-06 08:09:00+00:00', '2012-03-06 09:09:00+00:00'],\n              dtype='datetime64[ns, Europe/London]', freq='H')\n\n\n\n\n(2) timezone using dateutil\n\ntd = pd.date_range('3/6/2012 00:00', periods=10, freq='H',tz='dateutil/Europe/London')\ntd\n\nDatetimeIndex(['2012-03-06 00:00:00+00:00', '2012-03-06 01:00:00+00:00',\n               '2012-03-06 02:00:00+00:00', '2012-03-06 03:00:00+00:00',\n               '2012-03-06 04:00:00+00:00', '2012-03-06 05:00:00+00:00',\n               '2012-03-06 06:00:00+00:00', '2012-03-06 07:00:00+00:00',\n               '2012-03-06 08:00:00+00:00', '2012-03-06 09:00:00+00:00'],\n              dtype='datetime64[ns, tzfile('/usr/share/zoneinfo/Europe/London')]', freq='H')\n\n\n\n\n\nAirthmetic between different timezones\n\nrng = pd.date_range(start=\"2017-08-22 09:00:00\",periods=10, freq='30min')\ns = pd.Series(range(10),index=rng)\ns\n\n2017-08-22 09:00:00    0\n2017-08-22 09:30:00    1\n2017-08-22 10:00:00    2\n2017-08-22 10:30:00    3\n2017-08-22 11:00:00    4\n2017-08-22 11:30:00    5\n2017-08-22 12:00:00    6\n2017-08-22 12:30:00    7\n2017-08-22 13:00:00    8\n2017-08-22 13:30:00    9\nFreq: 30T, dtype: int64\n\n\n\nb = s.tz_localize(tz=\"Europe/Berlin\")\nb\n\n2017-08-22 09:00:00+02:00    0\n2017-08-22 09:30:00+02:00    1\n2017-08-22 10:00:00+02:00    2\n2017-08-22 10:30:00+02:00    3\n2017-08-22 11:00:00+02:00    4\n2017-08-22 11:30:00+02:00    5\n2017-08-22 12:00:00+02:00    6\n2017-08-22 12:30:00+02:00    7\n2017-08-22 13:00:00+02:00    8\n2017-08-22 13:30:00+02:00    9\ndtype: int64\n\n\n\nb.index\n\nDatetimeIndex(['2017-08-22 09:00:00+02:00', '2017-08-22 09:30:00+02:00',\n               '2017-08-22 10:00:00+02:00', '2017-08-22 10:30:00+02:00',\n               '2017-08-22 11:00:00+02:00', '2017-08-22 11:30:00+02:00',\n               '2017-08-22 12:00:00+02:00', '2017-08-22 12:30:00+02:00',\n               '2017-08-22 13:00:00+02:00', '2017-08-22 13:30:00+02:00'],\n              dtype='datetime64[ns, Europe/Berlin]', freq=None)\n\n\n\nm = s.tz_localize(tz=\"Asia/Calcutta\")\nm.index\n\nDatetimeIndex(['2017-08-22 09:00:00+05:30', '2017-08-22 09:30:00+05:30',\n               '2017-08-22 10:00:00+05:30', '2017-08-22 10:30:00+05:30',\n               '2017-08-22 11:00:00+05:30', '2017-08-22 11:30:00+05:30',\n               '2017-08-22 12:00:00+05:30', '2017-08-22 12:30:00+05:30',\n               '2017-08-22 13:00:00+05:30', '2017-08-22 13:30:00+05:30'],\n              dtype='datetime64[ns, Asia/Calcutta]', freq=None)\n\n\n\nm\n\n2017-08-22 09:00:00+05:30    0\n2017-08-22 09:30:00+05:30    1\n2017-08-22 10:00:00+05:30    2\n2017-08-22 10:30:00+05:30    3\n2017-08-22 11:00:00+05:30    4\n2017-08-22 11:30:00+05:30    5\n2017-08-22 12:00:00+05:30    6\n2017-08-22 12:30:00+05:30    7\n2017-08-22 13:00:00+05:30    8\n2017-08-22 13:30:00+05:30    9\ndtype: int64\n\n\n\nb + m\n\n2017-08-22 03:30:00+00:00     NaN\n2017-08-22 04:00:00+00:00     NaN\n2017-08-22 04:30:00+00:00     NaN\n2017-08-22 05:00:00+00:00     NaN\n2017-08-22 05:30:00+00:00     NaN\n2017-08-22 06:00:00+00:00     NaN\n2017-08-22 06:30:00+00:00     NaN\n2017-08-22 07:00:00+00:00     7.0\n2017-08-22 07:30:00+00:00     9.0\n2017-08-22 08:00:00+00:00    11.0\n2017-08-22 08:30:00+00:00     NaN\n2017-08-22 09:00:00+00:00     NaN\n2017-08-22 09:30:00+00:00     NaN\n2017-08-22 10:00:00+00:00     NaN\n2017-08-22 10:30:00+00:00     NaN\n2017-08-22 11:00:00+00:00     NaN\n2017-08-22 11:30:00+00:00     NaN\ndtype: float64"
  },
  {
    "objectID": "pandas.html#shifting-and-lagging",
    "href": "pandas.html#shifting-and-lagging",
    "title": "Pandas",
    "section": "Shifting and Lagging",
    "text": "Shifting and Lagging\n\nimport pandas as pd\ndf = pd.read_csv(\"Data/fb.csv\",parse_dates=['Date'],index_col='Date')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\n171.00\n\n\n2017-08-16\n170.00\n\n\n2017-08-17\n166.91\n\n\n2017-08-18\n167.41\n\n\n2017-08-21\n167.78\n\n\n2017-08-22\n169.64\n\n\n2017-08-23\n168.71\n\n\n2017-08-24\n167.74\n\n\n2017-08-25\n166.32\n\n\n2017-08-28\n167.24\n\n\n\n\n\n\n\n\ndf.shift(1)\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\nNaN\n\n\n2017-08-16\n171.00\n\n\n2017-08-17\n170.00\n\n\n2017-08-18\n166.91\n\n\n2017-08-21\n167.41\n\n\n2017-08-22\n167.78\n\n\n2017-08-23\n169.64\n\n\n2017-08-24\n168.71\n\n\n2017-08-25\n167.74\n\n\n2017-08-28\n166.32\n\n\n\n\n\n\n\n\ndf.shift(-1)\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\n170.00\n\n\n2017-08-16\n166.91\n\n\n2017-08-17\n167.41\n\n\n2017-08-18\n167.78\n\n\n2017-08-21\n169.64\n\n\n2017-08-22\n168.71\n\n\n2017-08-23\n167.74\n\n\n2017-08-24\n166.32\n\n\n2017-08-25\n167.24\n\n\n2017-08-28\nNaN\n\n\n\n\n\n\n\n\ndf['Prev Day Price'] = df['Price'].shift(1)\ndf\n\n\n\n\n\n\n\n\nPrice\nPrev Day Price\n\n\nDate\n\n\n\n\n\n\n2017-08-15\n171.00\nNaN\n\n\n2017-08-16\n170.00\n171.00\n\n\n2017-08-17\n166.91\n170.00\n\n\n2017-08-18\n167.41\n166.91\n\n\n2017-08-21\n167.78\n167.41\n\n\n2017-08-22\n169.64\n167.78\n\n\n2017-08-23\n168.71\n169.64\n\n\n2017-08-24\n167.74\n168.71\n\n\n2017-08-25\n166.32\n167.74\n\n\n2017-08-28\n167.24\n166.32\n\n\n\n\n\n\n\n\ndf['Price Change'] = df['Price'] - df['Prev Day Price']\ndf\n\n\n\n\n\n\n\n\nPrice\nPrev Day Price\nPrice Change\n\n\nDate\n\n\n\n\n\n\n\n2017-08-15\n171.00\nNaN\nNaN\n\n\n2017-08-16\n170.00\n171.00\n-1.00\n\n\n2017-08-17\n166.91\n170.00\n-3.09\n\n\n2017-08-18\n167.41\n166.91\n0.50\n\n\n2017-08-21\n167.78\n167.41\n0.37\n\n\n2017-08-22\n169.64\n167.78\n1.86\n\n\n2017-08-23\n168.71\n169.64\n-0.93\n\n\n2017-08-24\n167.74\n168.71\n-0.97\n\n\n2017-08-25\n166.32\n167.74\n-1.42\n\n\n2017-08-28\n167.24\n166.32\n0.92\n\n\n\n\n\n\n\n\ndf['5 day return'] =  (df['Price'] - df['Price'].shift(5))*100/df['Price'].shift(5)\ndf\n\n\n\n\n\n\n\n\nPrice\nPrev Day Price\nPrice Change\n5 day return\n\n\nDate\n\n\n\n\n\n\n\n\n2017-08-15\n171.00\nNaN\nNaN\nNaN\n\n\n2017-08-16\n170.00\n171.00\n-1.00\nNaN\n\n\n2017-08-17\n166.91\n170.00\n-3.09\nNaN\n\n\n2017-08-18\n167.41\n166.91\n0.50\nNaN\n\n\n2017-08-21\n167.78\n167.41\n0.37\nNaN\n\n\n2017-08-22\n169.64\n167.78\n1.86\n-0.795322\n\n\n2017-08-23\n168.71\n169.64\n-0.93\n-0.758824\n\n\n2017-08-24\n167.74\n168.71\n-0.97\n0.497274\n\n\n2017-08-25\n166.32\n167.74\n-1.42\n-0.651096\n\n\n2017-08-28\n167.24\n166.32\n0.92\n-0.321850\n\n\n\n\n\n\n\n\ndf = df[['Price']]\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\nDate\n\n\n\n\n\n2017-08-15\n171.00\n\n\n2017-08-16\n170.00\n\n\n2017-08-17\n166.91\n\n\n2017-08-18\n167.41\n\n\n2017-08-21\n167.78\n\n\n2017-08-22\n169.64\n\n\n2017-08-23\n168.71\n\n\n2017-08-24\n167.74\n\n\n2017-08-25\n166.32\n\n\n2017-08-28\n167.24\n\n\n\n\n\n\n\n\ntshift\n\ndf.index\n\nDatetimeIndex(['2017-08-15', '2017-08-16', '2017-08-17', '2017-08-18',\n               '2017-08-21', '2017-08-22', '2017-08-23', '2017-08-24',\n               '2017-08-25', '2017-08-28'],\n              dtype='datetime64[ns]', name='Date', freq=None)\n\n\n\ndf.index = pd.date_range(start='2017-08-15',periods=10, freq='B')\ndf\n\n\n\n\n\n\n\n\nPrice\n\n\n\n\n2017-08-15\n171.00\n\n\n2017-08-16\n170.00\n\n\n2017-08-17\n166.91\n\n\n2017-08-18\n167.41\n\n\n2017-08-21\n167.78\n\n\n2017-08-22\n169.64\n\n\n2017-08-23\n168.71\n\n\n2017-08-24\n167.74\n\n\n2017-08-25\n166.32\n\n\n2017-08-28\n167.24\n\n\n\n\n\n\n\n\ndf.index\n\nDatetimeIndex(['2017-08-15', '2017-08-16', '2017-08-17', '2017-08-18',\n               '2017-08-21', '2017-08-22', '2017-08-23', '2017-08-24',\n               '2017-08-25', '2017-08-28'],\n              dtype='datetime64[ns]', freq='B')"
  },
  {
    "objectID": "mito.html",
    "href": "mito.html",
    "title": "Mito",
    "section": "",
    "text": "!pip list | grep mitosheet\n\nmitosheet                     0.1.530\n\n\n\nimport mitosheet\n\n\nmitosheet.sheet(analysis_to_replay=\"id-qdjqkelpwx\")\n\n\n\n        \n    \n\n\n\nfrom mitosheet.public.v3 import *; # Analysis Name:id-qdjqkelpwx;\nimport pandas as pd\n\n# Imported salaries.csv\nsalaries = pd.read_csv(r'/home/ben/BENEDICT_Only/Benedict_Projects/Benedict_ML/ML/nbs/Data/salaries.csv')\n\n# sort the column company in ascending order\nsalaries.sort_values('company', ascending=True, inplace=True)\n\n\n\n\n Back to top"
  },
  {
    "objectID": "scipy.html",
    "href": "scipy.html",
    "title": "Scipy",
    "section": "",
    "text": "Back to top"
  }
]